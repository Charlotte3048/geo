import json
import re
import yaml
import argparse
import time
import math
from collections import defaultdict

# ==============================================================================
# å›½å†…æ¦œå•åˆ†æå¼•æ“ (ç®€åŒ–ç‰ˆ - åªç”Ÿæˆæ€»æ¦œå•)
# æè¿°: ä¸“é—¨ç”¨äºå›½å†…æ¦œå•åˆ†æï¼Œä¸åˆ†å­å“ç±»ï¼Œåªç”Ÿæˆä¸€ä¸ªæ€»æ¦œå•
# ç”¨æ³•: python analyze_results_domestic.py --task scenic --results results_scenic_merged.json --brands brand_dictionary_scenic.yaml
# python analyze_results_domestic.py --task nev --results results_nev_merged.json --brands brand_dictionary_nev.yaml
# python analyze_results_domestic.py --task phone --results results_phone_merged.json --brands brand_dictionary_phone.yaml
# python analyze_results_domestic.py --task food --results results_food_merged.json --brands brand_dictionary_food.yaml
# python analyze_results_domestic.py --task snack --results merged_results/results_snack_merged.json --brands config/brand_dictionary_snack.yaml
# python analyze_results_domestic.py --task city --results results_city_merged.json --brands brand_dictionary_city.yaml
# python analyze_results_domestic.py --task luxury --results results_luxury_merged.json --brands brand_dictionary_luxury.yaml
# python analyze_results_domestic.py --task beauty --results results_beauty_merged.json --brands brand_dictionary_beauty.yaml
# python analyze_results_domestic.py --task travel --results results_merged_ts.json --brands config/brand_dictionary_ts_travel.yaml
# python analyze_results_domestic.py --task tc_city --results /Users/charlotte/PycharmProjects/GEO/oversea/results_merged_tc.json --brands brand_dictionary_tc.yaml
# ==============================================================================


# å¯¼å…¥BERTæƒ…æ„Ÿåˆ†ææ¨¡å—
try:
    from domestic.sentiment.sentiment_analyzer import get_sentiment_analyzer

    USE_BERT_SENTIMENT = True
    print("âœ… BERTæƒ…æ„Ÿåˆ†ææ¨¡å—å·²å¯ç”¨")
except ImportError as e:
    USE_BERT_SENTIMENT = False
    print(f"âš ï¸  BERTæƒ…æ„Ÿåˆ†ææ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨è§„åˆ™åŒ¹é…æ–¹å¼: {e}")


def analyze_single_answer(answer_text: str, references: list, brand_map: dict):
    """åˆ†æå•ä¸ªå›ç­”ï¼Œæå–å“ç‰Œç›¸å…³æŒ‡æ ‡"""
    raw_metrics = defaultdict(
        lambda: {"mentioned": 0, "first_pos": float('inf'), "is_strong": 0, "ref_count": 0, "mention_count": 0,
                 "top10_points": 0, "sentiment_sentences": []})  # æ–°å¢ï¼šå­˜å‚¨åŒ…å«å“ç‰Œçš„å¥å­
    answer_lower = answer_text.lower()

    # --- 1. æ£€æµ‹å“ç‰ŒæåŠå¹¶è®¡ç®— first_pos ---
    brand_mentions_with_pos = []
    for std_brand, aliases in brand_map.items():
        for alias in aliases:
            alias_lower = alias.lower()
            # Find all occurrences of the alias
            for match in re.finditer(re.escape(alias_lower), answer_lower):
                raw_metrics[std_brand]["mentioned"] = 1
                raw_metrics[std_brand]["mention_count"] += 1  # æ¯æ¬¡åŒ¹é…éƒ½ç®—ä¸€æ¬¡æåŠ

                pos = match.start()
                if pos < raw_metrics[std_brand]["first_pos"]:
                    raw_metrics[std_brand]["first_pos"] = pos

                # æ”¶é›†æ‰€æœ‰é¦–æ¬¡æåŠçš„ä½ç½®ï¼Œç”¨äºè®¡ç®— Top 10 ç§¯åˆ†
                brand_mentions_with_pos.append({
                    "brand": std_brand,
                    "pos": pos
                })

    # --- 2. è®¡ç®— Top 10 ç§¯åˆ† (å‰10å¯è§åº¦) ---
    # æ‰¾åˆ°æ¯ä¸ªå“ç‰Œçš„é¦–æ¬¡å‡ºç°ä½ç½®
    first_mention_positions = {}
    for mention in brand_mentions_with_pos:
        brand = mention["brand"]
        pos = mention["pos"]
        if brand not in first_mention_positions or pos < first_mention_positions[brand]:
            first_mention_positions[brand] = pos

    # å°†å“ç‰ŒæŒ‰é¦–æ¬¡å‡ºç°ä½ç½®æ’åº
    sorted_brands_by_pos = sorted(first_mention_positions.items(), key=lambda item: item[1])

    # ç»™å‰ 10 ä¸ªå“ç‰Œåˆ†é…ç§¯åˆ†
    for rank, (brand, pos) in enumerate(sorted_brands_by_pos):
        if rank < 10:  # æ’åä» 0 å¼€å§‹ï¼Œæ‰€ä»¥ < 10 æ˜¯å‰ 10 ä¸ª
            points = 10 - rank  # 1st (rank 0) gets 10, 10th (rank 9) gets 1
            raw_metrics[brand]["top10_points"] = points
        else:
            break  # è¶…è¿‡ 10 ä¸ªå“ç‰Œååœæ­¢è®¡åˆ†

    # --- 3. æå–åŒ…å«å“ç‰Œçš„å¥å­ï¼ˆç”¨äºBERTæƒ…æ„Ÿåˆ†æï¼‰---
    sentences = re.split(r'[ã€‚\n.!?]', answer_text)  # æŒ‰å¥å­åˆ†å‰²

    for sentence in sentences:
        sentence_lower = sentence.lower().strip()
        if not sentence_lower:
            continue

        for brand, metrics in raw_metrics.items():
            if not metrics["mentioned"]:
                continue
            # æ£€æŸ¥å¥å­ä¸­æ˜¯å¦åŒ…å«è¯¥å“ç‰Œ
            if brand.lower() in sentence_lower:
                # å°†åŒ…å«å“ç‰Œçš„å¥å­å­˜å‚¨èµ·æ¥
                raw_metrics[brand]["sentiment_sentences"].append(sentence)

    # --- 4. æ£€æµ‹å¼ºæ¨è (is_strong) - ä¿ç•™ä½œä¸ºå¤‡ç”¨ ---
    strong_patterns = [
        r"(å¼ºçƒˆ)?æ¨è", r"é¦–é€‰", r"æœ€ä½³", r"å€¼å¾—.*?(å°è¯•|è´­ä¹°|é€‰æ‹©)",
        r"æ€§ä»·æ¯”.*?(é«˜|å¾ˆé«˜)", r"(æ˜¯|å±)?(top|best)[^ã€‚]*?(å“ç‰Œ|é€‰æ‹©|ä¹‹ä¸€)",
        r"(æˆ‘|æˆ‘ä»¬)?(æœ€|å¾ˆ)?å¸¸ä¹°", r"(ä¸ªäºº|æˆ‘)?è§‰å¾—.*?(æœ€å¥½|æœ€æ¨è)"
    ]
    negation_keywords = ["ä¸æ¨è", "ä¸å¤ª", "ä¸å–œæ¬¢", "ä¸å€¼å¾—", "è¸©é›·", "é¿å‘", "æœ€å·®", "ä¸åˆé€‚", "ä¸å¦‚"]

    for sentence in sentences:
        sentence_lower = sentence.lower()
        for brand, metrics in raw_metrics.items():
            if not metrics["mentioned"]:
                continue
            if brand.lower() in sentence_lower:
                if any(re.search(p, sentence_lower) for p in strong_patterns):
                    if not any(neg in sentence_lower for neg in negation_keywords):
                        raw_metrics[brand]["is_strong"] = 1

    return raw_metrics


def safe_log1p_scaled(x, k=1000, scale=10):
    """å¯¹å°æ•°xè¿›è¡Œå¹³æ»‘æ”¾å¤§å’Œå¯¹æ•°ç¼©æ”¾ï¼Œé¿å…è´Ÿå€¼"""
    return math.log1p(x * k) * scale


def calculate_scores(data_list,
                     brand_dictionary,
                     whitelist,
                     weights,
                     return_question_level: bool = False,
                     analyzer=None) -> dict:
    question_level_details = []

    """è®¡ç®—æ‰€æœ‰å“ç‰Œçš„å¾—åˆ†ï¼ˆé›†æˆBERTæƒ…æ„Ÿåˆ†æï¼‰"""
    all_brands_raw_metrics = defaultdict(
        lambda: {"total_mentions": 0, "first_pos_sum": 0, "top10_score_sum": 0, "strong_recommend_count": 0,
                 "total_ref_count": 0, "mention_in_answers": 0, "sentiment_sentences": []})  # æ–°å¢
    total_brand_mentions_across_all = 0

    # æ”¶é›†æ‰€æœ‰åŸå§‹æŒ‡æ ‡
    for item in data_list:
        answer = item.get("response", {}).get("answer", "")
        references = item.get("response", {}).get("references", [])
        if not answer:
            continue

        answer_metrics = analyze_single_answer(answer, references, brand_dictionary)

        for brand, metrics in answer_metrics.items():
            if brand in whitelist:
                brand_global_metrics = all_brands_raw_metrics[brand]
                brand_global_metrics["total_mentions"] += metrics["mention_count"]
                if metrics["first_pos"] != float('inf'):
                    brand_global_metrics["first_pos_sum"] += metrics["first_pos"]
                brand_global_metrics["strong_recommend_count"] += metrics["is_strong"]
                brand_global_metrics["top10_score_sum"] += metrics["top10_points"]
                brand_global_metrics["total_ref_count"] += metrics["ref_count"]
                brand_global_metrics["mention_in_answers"] += 1
                total_brand_mentions_across_all += metrics["mention_count"]

                # æ”¶é›†æƒ…æ„Ÿåˆ†æå¥å­
                brand_global_metrics["sentiment_sentences"].extend(metrics["sentiment_sentences"])

    if not all_brands_raw_metrics:
        return {}

    # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨æ³¨å…¥çš„ analyzerï¼ˆä¾‹å¦‚ scoring_pipeline çš„ singletonï¼‰
    sentiment_analyzer = analyzer

    # å¦‚æœå¤–éƒ¨æ²¡ä¼ ï¼Œå†æŒ‰ä½ åŸæ¥çš„é€»è¾‘åˆå§‹åŒ–ï¼ˆä¿æŒå…¼å®¹ï¼‰
    if sentiment_analyzer is None and USE_BERT_SENTIMENT:
        try:
            sentiment_analyzer = get_sentiment_analyzer()
            print("ğŸ¤– ä½¿ç”¨BERTæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ...")
        except Exception as e:
            print(f"âš ï¸  BERTæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™åŒ¹é…: {e}")
            sentiment_analyzer = None

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    max_mentions = max((m["total_mentions"] for m in all_brands_raw_metrics.values()), default=1)
    max_strong = max((m["strong_recommend_count"] for m in all_brands_raw_metrics.values()), default=1)

    # è®¡ç®—æ¯ä¸ªå“ç‰Œçš„å¾—åˆ†
    final_scores = {}
    for brand, metrics in all_brands_raw_metrics.items():
        avg_pos = metrics["first_pos_sum"] / metrics["mention_in_answers"] if metrics[
                                                                                  "mention_in_answers"] > 0 else float(
            'inf')
        mention_density = metrics["total_mentions"] / metrics["mention_in_answers"] if metrics[
                                                                                           "mention_in_answers"] > 0 else 0

        # 1. å“ç‰Œå›ç­”æ˜¾è‘—åº¦
        if avg_pos == float('inf'):
            score_visibility = 0
        elif avg_pos < 500:
            score_visibility = 100
        elif avg_pos < 1500:
            score_visibility = 100 * (1 - (avg_pos - 500) / 1000)
        else:
            score_visibility = 0

        # 2. å£°é‡å æ¯” share of voice
        normalized_mind_share = metrics["total_mentions"] / total_brand_mentions_across_all
        share_of_voice = safe_log1p_scaled(normalized_mind_share, k=1000, scale=20)

        # 3. å‰10å¯è§åº¦
        max_top10_score = max((m["top10_score_sum"] for m in all_brands_raw_metrics.values()), default=1)
        normalized_top10 = (metrics["top10_score_sum"] + 1) / (max_top10_score + 1)
        top10_visibility = math.sqrt(normalized_top10) * 100

        # 4. ç«äº‰åŠ›æŒ‡æ•°
        competitiveness = (metrics["total_mentions"] / max_mentions) * 100 if max_mentions > 0 else 0

        # 5. æƒ…æ„Ÿåˆ†æ (BERTæ¨¡å‹ or è§„åˆ™åŒ¹é…)
        if sentiment_analyzer and metrics["sentiment_sentences"]:
            # ä½¿ç”¨BERTæ¨¡å‹åˆ†æï¼ˆé™åˆ¶æœ€å¤š50ä¸ªå¥å­ä»¥æé«˜æ€§èƒ½ï¼‰
            sentences_to_analyze = metrics["sentiment_sentences"][:50]
            results = sentiment_analyzer.predict(sentences_to_analyze)
            sentiment_scores = [r["score"] for r in results]
            sentiment_analysis = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 50.0
        else:
            # ä½¿ç”¨è§„åˆ™åŒ¹é…æ–¹å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            normalized_strong = (metrics["strong_recommend_count"] + 1) / (max_strong + 1)
            sentiment_analysis = math.sqrt(normalized_strong) * 100

        # åŠ æƒå¹³å‡
        w_brand_prominence = (
            weights.get("brand_prominence")
            if "brand_prominence" in weights
            else weights.get("visibility", 0)
        )

        w_share_of_voice = weights.get("share_of_voice", 0)
        w_top10_visibility = weights.get("top10_visibility", 0)
        w_competitiveness = weights.get("competitiveness", 0)
        w_sentiment = weights.get("sentiment_analysis", 0)

        total_score = (
                              score_visibility * w_brand_prominence +
                              share_of_voice * w_share_of_voice +
                              top10_visibility * w_top10_visibility +
                              competitiveness * w_competitiveness +
                              sentiment_analysis * w_sentiment
                      ) / 100

        final_scores[brand] = {
            "å“ç‰ŒæŒ‡æ•°": total_score,
            "æ€»æåŠæ¬¡æ•°": metrics["total_mentions"],
            "å‡ºç°æ¬¡æ•°": metrics["mention_in_answers"],
            "å¼ºæ¨èæ¬¡æ•°": metrics["strong_recommend_count"],
            "å¹³å‡æåŠå¯†åº¦": mention_density,
            "ç»´åº¦å¾—åˆ†": {
                "brand_prominence": score_visibility,
                "share_of_voice": share_of_voice,
                "top10_visibility": top10_visibility,
                "competitiveness": competitiveness,
                "sentiment_analysis": sentiment_analysis
            }
        }

    if return_question_level:
        return final_scores, question_level_details
    return final_scores


def write_ranking_report(output_file: str, title: str, scores: dict, task_name: str):
    """ç”ŸæˆMarkdownæ ¼å¼çš„æ’åæŠ¥å‘Š"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# {title}\n\n")
        f.write(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**åˆ†æä»»åŠ¡**: {task_name}\n\n")
        f.write("---\n\n")

        if not scores:
            f.write("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å“ç‰Œå¾—åˆ†æ•°æ®ã€‚\n\n")
            return

        # æ€»æ¦œå•è¡¨æ ¼
        f.write("## ğŸ“Š å“ç‰Œæ’åæ€»æ¦œå•\n\n")
        f.write(
            "| æ’å | å“ç‰Œåç§° | å“ç‰ŒæŒ‡æ•° | æ€»æåŠæ¬¡æ•° | å‡ºç°æ¬¡æ•° | å¼ºæ¨èæ¬¡æ•° | å“ç‰Œå›ç­”æ˜¾è‘—åº¦ | å£°é‡å æ¯” | å‰10å¯è§åº¦ | ç«äº‰åŠ›æŒ‡æ•° | æƒ…æ„Ÿåˆ†æ |\n")
        f.write("|:---:|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n")

        sorted_brands = sorted(scores.items(), key=lambda x: x[1]["å“ç‰ŒæŒ‡æ•°"], reverse=True)

        for rank, (brand, data) in enumerate(sorted_brands, 1):
            dims = data["ç»´åº¦å¾—åˆ†"]

            # ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½åœ¨ä¸€ä¸ª f.write è°ƒç”¨ä¸­ï¼Œå¹¶ä»¥æ¢è¡Œç¬¦ç»“æŸ
            row_content = (
                f"| {rank} | {brand} | **{data['å“ç‰ŒæŒ‡æ•°']:.2f}** | "
                f"{data['æ€»æåŠæ¬¡æ•°']} | {data['å‡ºç°æ¬¡æ•°']} | {data['å¼ºæ¨èæ¬¡æ•°']} | "
                f"{dims['brand_prominence']:.1f} | {dims['share_of_voice']:.1f} | {dims['top10_visibility']:.1f} | "
                f"{dims['competitiveness']:.1f} | {dims['sentiment_analysis']:.1f} |"
            )
            f.write(row_content + "\n")  # ç¡®ä¿æ¯è¡Œéƒ½æœ‰ä¸€ä¸ªæ¢è¡Œç¬¦

        # ç»Ÿè®¡ä¿¡æ¯
        f.write("## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯\n\n")
        f.write(f"- **å‚ä¸æ’åå“ç‰Œæ•°**: {len(scores)}\n")
        f.write(f"- **æœ€é«˜å“ç‰ŒæŒ‡æ•°**: {sorted_brands[0][1]['å“ç‰ŒæŒ‡æ•°']:.2f} ({sorted_brands[0][0]})\n")
        f.write(f"- **å¹³å‡å“ç‰ŒæŒ‡æ•°**: {sum(s['å“ç‰ŒæŒ‡æ•°'] for s in scores.values()) / len(scores):.2f}\n")
        f.write(f"- **æ€»æåŠæ¬¡æ•°**: {sum(s['æ€»æåŠæ¬¡æ•°'] for s in scores.values())}\n")
        f.write("\n")

        # è¯´æ˜
        f.write("## ğŸ“ è¯„åˆ†è¯´æ˜\n\n")
        f.write("æœ¬æ¦œå•é‡‡ç”¨äº”ç»´åº¦è¯„åˆ†ä½“ç³»ï¼Œæ¯ä¸ªæŒ‡æ ‡å„å 20%æƒé‡ï¼š\n\n")
        f.write("1. **å“ç‰Œå›ç­”æ˜¾è‘—åº¦**: å“ç‰Œåœ¨å¤§æ¨¡å‹å›ç­”ä¸­å‡ºç°çš„ä½ç½®ï¼Œä½ç½®è¶Šé å‰ï¼Œåˆ†æ•°è¶Šé«˜\n")
        f.write("2. **å£°é‡å æ¯”**: å“ç‰Œå¼•ç”¨æ¬¡æ•°ä¸æ‰€æœ‰å¼•ç”¨æ¬¡æ•°çš„æ¯”ç‡\n")
        f.write(
            "3. **å‰10å¯è§åº¦**: å“ç‰Œåœ¨å¤§æ¨¡å‹å›ç­”ä¸­åœ¨å‰ååä¸­å‡ºç°çš„æ•ˆæœï¼Œåæ¬¡è¶Šé«˜åˆ†æ•°è¶Šé«˜ï¼Œ10åˆ†ä¸€æ¡£ï¼Œè¶…å‡ºå‰ååä¸è®¡åˆ†\n")
        f.write("4. **ç«äº‰åŠ›æŒ‡æ•°**: å“ç‰Œä¸æåŠç‡æœ€é«˜çš„å“ç‰Œçš„æåŠç‡åªæ¯”ï¼Œåæ˜ äº†å“ç‰Œåœ¨å¸‚åœºä¸Šçš„ç«äº‰åŠ›â€ã€‚\n")
        f.write("5. **æƒ…æ„Ÿåˆ†æ**: å¤§æ¨¡å‹å›ç­”ä¸­å…³äºå“ç‰Œæ­£/è´Ÿé¢å†…å®¹åˆ†æ\n")
        f.write("\n")


def main():
    parser = argparse.ArgumentParser(description="å›½å†…æ¦œå•åˆ†æå¼•æ“")
    parser.add_argument("--task", required=True, help="ä»»åŠ¡åç§° (ä¾‹å¦‚: nev, scenic)")
    parser.add_argument("--results", required=True, help="ç»“æœæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: results_nev_merged.json)")
    parser.add_argument("--brands", required=True, help="å“ç‰Œè¯å…¸æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: brand_dictionary_scenic.yaml)")
    parser.add_argument("--output", default=None, help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ranking_report_{task}.md)")
    args = parser.parse_args()

    # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if args.output is None:
        args.output = f"ranking_report_{args.task}.md"

    print(f"\n{'=' * 60}")
    print(f"å›½å†…æ¦œå•åˆ†æå¼•æ“")
    print(f"{'=' * 60}\n")
    print(f"ğŸ“‹ ä»»åŠ¡åç§°: {args.task}")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶: {args.results}")
    print(f"ğŸ“– å“ç‰Œè¯å…¸: {args.brands}")
    print(f"ğŸ“„ è¾“å‡ºæŠ¥å‘Š: {args.output}\n")

    # åŠ è½½å“ç‰Œè¯å…¸
    print("æ­£åœ¨åŠ è½½å“ç‰Œè¯å…¸...")
    try:
        with open(args.brands, 'r', encoding='utf-8') as f:
            brands_config = yaml.safe_load(f)
        brand_dictionary = brands_config['brand_dictionary']
        brands_whitelist = set(brands_config['brands_whitelist'])
        print(f"âœ… æˆåŠŸåŠ è½½ {len(brand_dictionary)} ä¸ªå“ç‰Œï¼Œç™½åå•åŒ…å« {len(brands_whitelist)} ä¸ªå“ç‰Œ\n")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: å“ç‰Œè¯å…¸æ–‡ä»¶ '{args.brands}' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½å“ç‰Œè¯å…¸æ—¶å‡ºé”™: {e}")
        return

    # åŠ è½½ç»“æœæ•°æ®
    print("æ­£åœ¨åŠ è½½ç»“æœæ•°æ®...")
    try:
        with open(args.results, 'r', encoding='utf-8') as f:
            data_list = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(data_list)} æ¡å›ç­”è®°å½•\n")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: ç»“æœæ–‡ä»¶ '{args.results}' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½ç»“æœæ•°æ®æ—¶å‡ºé”™: {e}")
        return

    # å®šä¹‰æƒé‡ï¼ˆä¸æµ·å¤–æ¦œå•å®Œå…¨ä¸€è‡´ï¼‰
    weights = {
        "brand_prominence": 20,
        "share_of_voice": 20,
        "top10_visibility": 20,
        "competitiveness": 20,
        "sentiment_analysis": 20,
    }

    # è®¡ç®—å¾—åˆ†
    print("æ­£åœ¨è®¡ç®—å“ç‰Œå¾—åˆ†...")
    scores = calculate_scores(data_list, brand_dictionary, brands_whitelist, weights)
    print(f"âœ… æˆåŠŸè®¡ç®— {len(scores)} ä¸ªå“ç‰Œçš„å¾—åˆ†\n")

    # ç”ŸæˆæŠ¥å‘Š
    print("æ­£åœ¨ç”Ÿæˆæ’åæŠ¥å‘Š...")
    report_title = f"{args.task.upper()} å“ç‰ŒGenAIè®¤çŸ¥æŒ‡æ•°æ’è¡Œæ¦œ"
    write_ranking_report(args.output, report_title, scores, args.task)
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}\n")

    # æ˜¾ç¤ºå‰10å
    if scores:
        print("ğŸ† Top 10 å“ç‰Œé¢„è§ˆ:")
        print("-" * 60)
        sorted_brands = sorted(scores.items(), key=lambda x: x[1]["å“ç‰ŒæŒ‡æ•°"], reverse=True)
        for rank, (brand, data) in enumerate(sorted_brands[:10], 1):
            print(f"  {rank:2d}. {brand:15s} - å“ç‰ŒæŒ‡æ•°: {data['å“ç‰ŒæŒ‡æ•°']:6.2f}")
        print("-" * 60)

    print(f"\n{'=' * 60}")
    print("åˆ†æå®Œæˆï¼")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
