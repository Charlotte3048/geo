import json
import os
import re
import math
import yaml
import argparse
from collections import Counter, defaultdict
import time
from collections import defaultdict
import numpy as np


# ==============================================================================
# å›½å†…æ¦œå•åˆ†æå¼•æ“ (ç®€åŒ–ç‰ˆ - åªç”Ÿæˆæ€»æ¦œå•)
# æè¿°: ä¸“é—¨ç”¨äºå›½å†…æ¦œå•åˆ†æï¼Œä¸åˆ†å­å“ç±»ï¼Œåªç”Ÿæˆä¸€ä¸ªæ€»æ¦œå•
# ç”¨æ³•: python analyze_results_domestic.py --task scenic --results results_scenic_merged.json --brands brand_dictionary_scenic.yaml
# python analyze_results_domestic.py --task nev --results results_nev_merged.json --brands brand_dictionary_nev.yaml
# python analyze_results_domestic.py --task phone --results results_phone_merged.json --brands brand_dictionary_phone.yaml
# python analyze_results_domestic.py --task food --results results_food_merged.json --brands brand_dictionary_food.yaml
# python analyze_results_domestic.py --task snack --results merged_results/results_snack_merged.json --brands config/brand_dictionary_snack.yaml
# python analyze_results_domestic.py --task city --results results_city_merged.json --brands brand_dictionary_city.yaml
# python analyze_results_domestic.py --task luxury --results results_luxury_merged.json --brands brand_dictionary_luxury.yaml
# python analyze_results_domestic.py --task beauty --results results_beauty_merged.json --brands brand_dictionary_beauty.yaml
# python analyze_results_domestic.py --task travel --results results_merged_ts.json --brands config/brand_dictionary_ts_travel.yaml
# python analyze_results_domestic.py --task tc_city --results /Users/charlotte/PycharmProjects/GEO/oversea/results_merged_tc.json --brands brand_dictionary_tc.yaml
# ==============================================================================


def analyze_single_answer(answer_text: str, references: list, brand_map: dict):
    """åˆ†æå•ä¸ªå›ç­”ï¼Œæå–å“ç‰Œç›¸å…³æŒ‡æ ‡"""
    raw_metrics = defaultdict(
        lambda: {"mentioned": 0, "first_pos": float('inf'), "is_strong": 0, "ref_count": 0, "mention_count": 0})
    answer_lower = answer_text.lower()

    # æ£€æµ‹å“ç‰ŒæåŠ
    for std_brand, aliases in brand_map.items():
        for alias in aliases:
            alias_lower = alias.lower()
            if alias_lower in answer_lower:
                raw_metrics[std_brand]["mentioned"] = 1
                raw_metrics[std_brand]["mention_count"] += answer_lower.count(alias_lower)
                try:
                    pos = answer_lower.index(alias_lower)
                    if pos < raw_metrics[std_brand]["first_pos"]:
                        raw_metrics[std_brand]["first_pos"] = pos
                except ValueError:
                    pass

    # æ£€æµ‹å¼ºæ¨è
    sentences = re.split(r'[ã€‚\n]', answer_text)

    strong_patterns = [
        r"(å¼ºçƒˆ)?æ¨è", r"é¦–é€‰", r"æœ€ä½³", r"å€¼å¾—.*?(å°è¯•|è´­ä¹°|é€‰æ‹©)",
        r"æ€§ä»·æ¯”.*?(é«˜|å¾ˆé«˜)", r"(æ˜¯|å±)?(top|best)[^ã€‚]*?(å“ç‰Œ|é€‰æ‹©|ä¹‹ä¸€)",
        r"(æˆ‘|æˆ‘ä»¬)?(æœ€|å¾ˆ)?å¸¸ä¹°", r"(ä¸ªäºº|æˆ‘)?è§‰å¾—.*?(æœ€å¥½|æœ€æ¨è)"
    ]
    negation_keywords = ["ä¸æ¨è", "ä¸å¤ª", "ä¸å–œæ¬¢", "ä¸å€¼å¾—", "è¸©é›·", "é¿å‘", "æœ€å·®", "ä¸åˆé€‚", "ä¸å¦‚"]

    for sentence in sentences:
        sentence_lower = sentence.lower()
        for brand, metrics in raw_metrics.items():
            if not metrics["mentioned"]:
                continue
            if brand.lower() in sentence_lower:
                if any(re.search(p, sentence_lower) for p in strong_patterns):
                    if not any(neg in sentence_lower for neg in negation_keywords):
                        raw_metrics[brand]["is_strong"] = 1

    # æ£€æµ‹å¼•ç”¨
    # if references:
    #     for brand, metrics in raw_metrics.items():
    #         if metrics["mentioned"]:
    #             for ref in references:
    #                 if brand.lower() in ref.lower():
    #                     raw_metrics[brand]["ref_count"] += 1

    return raw_metrics


import math
from collections import defaultdict


def safe_log1p_scaled(x, k=1000, scale=10):
    """å¯¹å°æ•°xè¿›è¡Œå¹³æ»‘æ”¾å¤§å’Œå¯¹æ•°ç¼©æ”¾ï¼Œé¿å…è´Ÿå€¼"""
    return math.log1p(x * k) * scale


def calculate_scores(data_list: list, brand_dictionary: dict, whitelist: set, weights: dict) -> dict:
    """è®¡ç®—æ‰€æœ‰å“ç‰Œçš„å¾—åˆ†ï¼ˆä¿ç•™åŸç»“æ„ï¼Œä»… mind_share ä½¿ç”¨ log å‹ç¼©ï¼‰"""
    all_brands_raw_metrics = defaultdict(
        lambda: {"total_mentions": 0, "first_pos_sum": 0, "strong_recommend_count": 0,
                 "total_ref_count": 0, "mention_in_answers": 0})
    total_brand_mentions_across_all = 0

    # æ”¶é›†æ‰€æœ‰åŸå§‹æŒ‡æ ‡
    for item in data_list:
        answer = item.get("response", {}).get("answer", "")
        references = item.get("response", {}).get("references", [])
        if not answer:
            continue

        answer_metrics = analyze_single_answer(answer, references, brand_dictionary)

        for brand, metrics in answer_metrics.items():
            if brand in whitelist:
                brand_global_metrics = all_brands_raw_metrics[brand]
                brand_global_metrics["total_mentions"] += metrics["mention_count"]
                if metrics["first_pos"] != float('inf'):
                    brand_global_metrics["first_pos_sum"] += metrics["first_pos"]
                brand_global_metrics["strong_recommend_count"] += metrics["is_strong"]
                brand_global_metrics["total_ref_count"] += metrics["ref_count"]
                brand_global_metrics["mention_in_answers"] += 1
                total_brand_mentions_across_all += metrics["mention_count"]

    if not all_brands_raw_metrics:
        return {}

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    max_mentions = max((m["total_mentions"] for m in all_brands_raw_metrics.values()), default=1)
    max_density = max((m["total_mentions"] / m["mention_in_answers"]
                       for m in all_brands_raw_metrics.values() if m["mention_in_answers"] > 0), default=1)
    max_strong = max((m["strong_recommend_count"] for m in all_brands_raw_metrics.values()), default=1)

    # è®¡ç®—æ¯ä¸ªå“ç‰Œçš„å¾—åˆ†
    final_scores = {}
    for brand, metrics in all_brands_raw_metrics.items():
        avg_pos = metrics["first_pos_sum"] / metrics["mention_in_answers"] if metrics[
                                                                                  "mention_in_answers"] > 0 else float(
            'inf')
        mention_density = metrics["total_mentions"] / metrics["mention_in_answers"] if metrics[
                                                                                           "mention_in_answers"] > 0 else 0

        # 1. å“ç‰Œå¯è§åº¦ï¼ˆå¯çº¿æ€§è§„åˆ™ï¼‰
        if avg_pos == float('inf'):
            score_visibility = 0
        elif avg_pos < 500:
            score_visibility = 100
        elif avg_pos < 1500:
            score_visibility = 100 * (1 - (avg_pos - 500) / 1000)
        else:
            score_visibility = 0

        # 2. å¼•ç”¨ç‡ï¼ˆæ€»æåŠæ¬¡æ•°ï¼‰
        score_mention_rate = (metrics["total_mentions"] / max_mentions) * 100 if max_mentions > 0 else 0

        # 3. AIè®¤çŸ¥æŒ‡æ•°ï¼ˆå¼ºæ¨èæ¬¡æ•°ï¼‰
        normalized_strong = (metrics["strong_recommend_count"] + 1) / (max_strong + 1)
        score_ai_ranking = math.sqrt(normalized_strong) * 100

        # 4. å¹³å‡å¼•ç”¨å¯†åº¦
        norm_density = mention_density / max_density
        score_ref_depth = safe_log1p_scaled(norm_density, k=1000)

        # 5. AIè®¤çŸ¥ä»½é¢ï¼ˆä»…æ­¤é¡¹ä½¿ç”¨ log(1 + kx) Ã— scaleï¼‰
        normalized_mind_share = metrics["total_mentions"] / total_brand_mentions_across_all
        score_mind_share = safe_log1p_scaled(normalized_mind_share, k=1000, scale=20)

        # åŠ æƒå¹³å‡
        total_score = (
                              score_visibility * weights["visibility"] +
                              score_mention_rate * weights["mention_rate"] +
                              score_ai_ranking * weights["ai_ranking"] +
                              score_ref_depth * weights["ref_depth"] +
                              score_mind_share * weights["mind_share"]
                      ) / 100 # åŠ å¸¸æ•°ä»¥é¿å…åˆ†æ•°è¿‡ä½

        final_scores[brand] = {
            "å“ç‰ŒæŒ‡æ•°": total_score,
            "æ€»æåŠæ¬¡æ•°": metrics["total_mentions"],
            "å‡ºç°æ¬¡æ•°": metrics["mention_in_answers"],
            "å¼ºæ¨èæ¬¡æ•°": metrics["strong_recommend_count"],
            "å¹³å‡æåŠå¯†åº¦": mention_density,
            "ç»´åº¦å¾—åˆ†": {
                "visibility": score_visibility,
                "mention_rate": score_mention_rate,
                "ai_ranking": score_ai_ranking,
                "ref_depth": score_ref_depth,
                "mind_share": score_mind_share
            }
        }

    return final_scores


def write_ranking_report(output_file: str, title: str, scores: dict, task_name: str):
    """ç”ŸæˆMarkdownæ ¼å¼çš„æ’åæŠ¥å‘Š"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# {title}\n\n")
        f.write(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**åˆ†æä»»åŠ¡**: {task_name}\n\n")
        f.write("---\n\n")

        if not scores:
            f.write("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å“ç‰Œå¾—åˆ†æ•°æ®ã€‚\n\n")
            return

        # æ€»æ¦œå•è¡¨æ ¼
        f.write("## ğŸ“Š å“ç‰Œæ’åæ€»æ¦œå•\n\n")
        f.write(
            "| æ’å | å“ç‰Œåç§° | å“ç‰ŒæŒ‡æ•° | æ€»æåŠæ¬¡æ•° | å‡ºç°æ¬¡æ•° | å¼ºæ¨èæ¬¡æ•° | å“ç‰Œå¯è§åº¦ | å¼•ç”¨ç‡ | å“ç‰ŒAIè®¤çŸ¥æŒ‡æ•° | å¹³å‡å¼•ç”¨å¯†åº¦ | ç«äº‰åŠ›æŒ‡æ•° |\n")
        f.write("|:---:|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n")

        sorted_brands = sorted(scores.items(), key=lambda x: x[1]["å“ç‰ŒæŒ‡æ•°"], reverse=True)

        for rank, (brand, data) in enumerate(sorted_brands, 1):
            dims = data["ç»´åº¦å¾—åˆ†"]

            f.write(
                f"| {rank} | {brand} | **{data['å“ç‰ŒæŒ‡æ•°']:.2f}** | "
                f"{data['æ€»æåŠæ¬¡æ•°']} | {data['å‡ºç°æ¬¡æ•°']} | {data['å¼ºæ¨èæ¬¡æ•°']} | "
                f"{dims['visibility']:.1f} | {dims['mention_rate']:.1f} | {dims['ai_ranking']:.1f} | "
                f"{dims['ref_depth']:.1f} | {dims['mind_share']:.1f} |\n"
            )

        f.write("\n---\n\n")

        # ç»Ÿè®¡ä¿¡æ¯
        f.write("## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯\n\n")
        f.write(f"- **å‚ä¸æ’åå“ç‰Œæ•°**: {len(scores)}\n")
        f.write(f"- **æœ€é«˜å“ç‰ŒæŒ‡æ•°**: {sorted_brands[0][1]['å“ç‰ŒæŒ‡æ•°']:.2f} ({sorted_brands[0][0]})\n")
        f.write(f"- **å¹³å‡å“ç‰ŒæŒ‡æ•°**: {sum(s['å“ç‰ŒæŒ‡æ•°'] for s in scores.values()) / len(scores):.2f}\n")
        f.write(f"- **æ€»æåŠæ¬¡æ•°**: {sum(s['æ€»æåŠæ¬¡æ•°'] for s in scores.values())}\n")
        f.write("\n")

        # è¯´æ˜
        f.write("## ğŸ“ è¯„åˆ†è¯´æ˜\n\n")
        f.write("æœ¬æ¦œå•é‡‡ç”¨äº”ç»´åº¦è¯„åˆ†ä½“ç³»ï¼Œæ¯ä¸ªæŒ‡æ ‡å„å 20%æƒé‡ï¼š\n\n")
        f.write("1. **å“ç‰Œå¯è§åº¦**: å“ç‰Œé¦–æ¬¡å‡ºç°çš„ä½ç½®è¶Šé å‰ï¼Œå¾—åˆ†è¶Šé«˜\n")
        f.write("2. **å¼•ç”¨ç‡**: å“ç‰Œè¢«æåŠçš„æ€»æ¬¡æ•°\n")
        f.write("3. **AIè®¤çŸ¥æŒ‡æ•°**: å“ç‰Œåœ¨â€œå¼ºæ¨èâ€å¥å¼ä¸­å‡ºç°çš„é¢‘æ¬¡\n")
        f.write("4. **å¹³å‡å¼•ç”¨å¯†åº¦**: æ¯æ¬¡å›ç­”ä¸­è¯¥å“ç‰Œå¹³å‡è¢«æåŠçš„æ¬¡æ•°ï¼Œè¡¡é‡è®¨è®ºçš„å¯†åº¦â€ã€‚\n")
        f.write("5. **AIè®¤çŸ¥ä»½é¢ **: å“ç‰Œåœ¨æ‰€æœ‰å“ç‰Œä¸­çš„è¢«æåŠå æ¯”\n")
        f.write("\n")


def main():
    parser = argparse.ArgumentParser(description="å›½å†…æ¦œå•åˆ†æå¼•æ“")
    parser.add_argument("--task", required=True, help="ä»»åŠ¡åç§° (ä¾‹å¦‚: nev, scenic)")
    parser.add_argument("--results", required=True, help="ç»“æœæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: results_nev_merged.json)")
    parser.add_argument("--brands", required=True, help="å“ç‰Œè¯å…¸æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: brand_dictionary_scenic.yaml)")
    parser.add_argument("--output", default=None, help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ranking_report_{task}.md)")
    args = parser.parse_args()

    # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if args.output is None:
        args.output = f"ranking_report_{args.task}.md"

    print(f"\n{'=' * 60}")
    print(f"å›½å†…æ¦œå•åˆ†æå¼•æ“")
    print(f"{'=' * 60}\n")
    print(f"ğŸ“‹ ä»»åŠ¡åç§°: {args.task}")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶: {args.results}")
    print(f"ğŸ“– å“ç‰Œè¯å…¸: {args.brands}")
    print(f"ğŸ“„ è¾“å‡ºæŠ¥å‘Š: {args.output}\n")

    # åŠ è½½å“ç‰Œè¯å…¸
    print("æ­£åœ¨åŠ è½½å“ç‰Œè¯å…¸...")
    try:
        with open(args.brands, 'r', encoding='utf-8') as f:
            brands_config = yaml.safe_load(f)
        brand_dictionary = brands_config['brand_dictionary']
        brands_whitelist = set(brands_config['brands_whitelist'])
        print(f"âœ… æˆåŠŸåŠ è½½ {len(brand_dictionary)} ä¸ªå“ç‰Œï¼Œç™½åå•åŒ…å« {len(brands_whitelist)} ä¸ªå“ç‰Œ\n")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: å“ç‰Œè¯å…¸æ–‡ä»¶ '{args.brands}' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½å“ç‰Œè¯å…¸æ—¶å‡ºé”™: {e}")
        return

    # åŠ è½½ç»“æœæ•°æ®
    print("æ­£åœ¨åŠ è½½ç»“æœæ•°æ®...")
    try:
        with open(args.results, 'r', encoding='utf-8') as f:
            data_list = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(data_list)} æ¡å›ç­”è®°å½•\n")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: ç»“æœæ–‡ä»¶ '{args.results}' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½ç»“æœæ•°æ®æ—¶å‡ºé”™: {e}")
        return

    # å®šä¹‰æƒé‡ï¼ˆä¸æµ·å¤–æ¦œå•å®Œå…¨ä¸€è‡´ï¼‰
    weights = {
        "visibility": 20,
        "mention_rate": 20,
        "ai_ranking": 20,
        "ref_depth": 20,
        "mind_share": 20,
    }

    # è®¡ç®—å¾—åˆ†
    print("æ­£åœ¨è®¡ç®—å“ç‰Œå¾—åˆ†...")
    scores = calculate_scores(data_list, brand_dictionary, brands_whitelist, weights)
    print(f"âœ… æˆåŠŸè®¡ç®— {len(scores)} ä¸ªå“ç‰Œçš„å¾—åˆ†\n")

    # ç”ŸæˆæŠ¥å‘Š
    print("æ­£åœ¨ç”Ÿæˆæ’åæŠ¥å‘Š...")
    report_title = f"{args.task.upper()} å“ç‰ŒGenAIè®¤çŸ¥æŒ‡æ•°æ’è¡Œæ¦œ"
    write_ranking_report(args.output, report_title, scores, args.task)
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}\n")

    # æ˜¾ç¤ºå‰10å
    if scores:
        print("ğŸ† Top 10 å“ç‰Œé¢„è§ˆ:")
        print("-" * 60)
        sorted_brands = sorted(scores.items(), key=lambda x: x[1]["å“ç‰ŒæŒ‡æ•°"], reverse=True)
        for rank, (brand, data) in enumerate(sorted_brands[:10], 1):
            print(f"  {rank:2d}. {brand:15s} - å“ç‰ŒæŒ‡æ•°: {data['å“ç‰ŒæŒ‡æ•°']:6.2f}")
        print("-" * 60)

    print(f"\n{'=' * 60}")
    print("åˆ†æå®Œæˆï¼")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
