import json
import os
import re
import math
import yaml
import argparse
from collections import Counter, defaultdict
import time


# ==============================================================================
# å›½å†…æ¦œå•åˆ†æå¼•æ“ (ç®€åŒ–ç‰ˆ - åªç”Ÿæˆæ€»æ¦œå•)
# æè¿°: ä¸“é—¨ç”¨äºå›½å†…æ¦œå•åˆ†æï¼Œä¸åˆ†å­å“ç±»ï¼Œåªç”Ÿæˆä¸€ä¸ªæ€»æ¦œå•
# ç”¨æ³•: python analyze_results_domestic.py --task nev --results results_nev_merged.json --brands brand_dictionary_nev.yaml
# ==============================================================================


def analyze_single_answer(answer_text: str, references: list, brand_map: dict):
    """åˆ†æå•ä¸ªå›ç­”ï¼Œæå–å“ç‰Œç›¸å…³æŒ‡æ ‡"""
    raw_metrics = defaultdict(
        lambda: {"mentioned": 0, "first_pos": float('inf'), "is_strong": 0, "ref_count": 0, "mention_count": 0})
    answer_lower = answer_text.lower()

    # æ£€æµ‹å“ç‰ŒæåŠ
    for std_brand, aliases in brand_map.items():
        for alias in aliases:
            alias_lower = alias.lower()
            if alias_lower in answer_lower:
                raw_metrics[std_brand]["mentioned"] = 1
                raw_metrics[std_brand]["mention_count"] += answer_lower.count(alias_lower)
                try:
                    pos = answer_lower.index(alias_lower)
                    if pos < raw_metrics[std_brand]["first_pos"]:
                        raw_metrics[std_brand]["first_pos"] = pos
                except ValueError:
                    pass

    # æ£€æµ‹å¼ºæ¨è
    sentences = re.split(r'[ã€‚\n]', answer_text)
    for sentence in sentences:
        sentence_lower = sentence.lower()
        for brand, metrics in raw_metrics.items():
            if metrics["mentioned"] and brand.lower() in sentence_lower:
                if any(word in sentence_lower for word in
                       ["é¦–é€‰", "æœ€ä½³", "å¼ºçƒˆæ¨è", "æ¨è", "å€¼å¾—", "best", "top", "recommended"]):
                    raw_metrics[brand]["is_strong"] = 1

    # æ£€æµ‹å¼•ç”¨
    if references:
        for brand, metrics in raw_metrics.items():
            if metrics["mentioned"]:
                for ref in references:
                    if brand.lower() in ref.lower():
                        raw_metrics[brand]["ref_count"] += 1

    return raw_metrics


def calculate_scores(data_list: list, brand_dictionary: dict, whitelist: set, weights: dict) -> dict:
    """è®¡ç®—æ‰€æœ‰å“ç‰Œçš„å¾—åˆ†ï¼ˆä¸¥æ ¼æŒ‰ç…§æµ·å¤–æ¦œå•æ ‡å‡†ï¼‰"""
    all_brands_raw_metrics = defaultdict(
        lambda: {"total_mentions": 0, "first_pos_sum": 0, "strong_recommend_count": 0,
                 "total_ref_count": 0, "mention_in_answers": 0})
    total_brand_mentions_across_all = 0

    # æ”¶é›†æ‰€æœ‰åŸå§‹æŒ‡æ ‡
    for item in data_list:
        answer = item.get("response", {}).get("answer", "")
        references = item.get("response", {}).get("references", [])
        if not answer:
            continue

        answer_metrics = analyze_single_answer(answer, references, brand_dictionary)

        for brand, metrics in answer_metrics.items():
            if brand in whitelist:
                brand_global_metrics = all_brands_raw_metrics[brand]
                brand_global_metrics["total_mentions"] += metrics["mention_count"]
                if metrics["first_pos"] != float('inf'):
                    brand_global_metrics["first_pos_sum"] += metrics["first_pos"]
                brand_global_metrics["strong_recommend_count"] += metrics["is_strong"]
                brand_global_metrics["total_ref_count"] += metrics["ref_count"]
                brand_global_metrics["mention_in_answers"] += 1
                total_brand_mentions_across_all += metrics["mention_count"]

    if not all_brands_raw_metrics:
        return {}

    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    max_mentions = max((m["total_mentions"] for m in all_brands_raw_metrics.values()), default=0)
    max_strong = max((m["strong_recommend_count"] for m in all_brands_raw_metrics.values()), default=0)
    max_refs = max((m["total_ref_count"] for m in all_brands_raw_metrics.values()), default=0)

    # è®¡ç®—æœ€å¤§å¹³å‡æåŠå¯†åº¦ï¼ˆç”¨äºæ›¿ä»£ref_depthï¼‰
    max_density = max((m["total_mentions"] / m["mention_in_answers"] for m in all_brands_raw_metrics.values()
                       if m["mention_in_answers"] > 0), default=1)

    # è®¡ç®—æ¯ä¸ªå“ç‰Œçš„å¾—åˆ†
    final_scores = {}
    for brand, metrics in all_brands_raw_metrics.items():
        avg_pos = metrics["first_pos_sum"] / metrics["mention_in_answers"] if metrics[
                                                                                  "mention_in_answers"] > 0 else float(
            'inf')

        # 1. å“ç‰Œå¯è§åº¦ (Visibility) - å®ä½“é¦–æ¬¡å‡ºç°çš„ä½ç½®è¶Šé å‰ï¼Œå¾—åˆ†è¶Šé«˜
        if avg_pos == float('inf'):
            score_visibility = 0
        elif avg_pos < 500:
            score_visibility = 100
        elif avg_pos < 1500:
            score_visibility = 100 * (1 - (avg_pos - 500) / 1000)  # çº¿æ€§é€’å‡
        else:
            score_visibility = 0

        # 2. å¼•ç”¨ç‡ (Mention Rate) - å®ä½“è¢«æåŠçš„æ€»æ¬¡æ•°
        score_mention_rate = (metrics["total_mentions"] / max_mentions) * 100 if max_mentions > 0 else 0

        # 3. AIè®¤çŸ¥æ’è¡ŒæŒ‡æ•° (AI Ranking) - åŸºäºå¼ºæ¨èæ¬¡æ•°
        normalized_strong = (metrics["strong_recommend_count"] + 1) / (max_strong + 1)
        score_ai_ranking = math.sqrt(normalized_strong) * 100

        # 4. æ­£æ–‡å¼•ç”¨æ·±åº¦ (Ref Depth) - æ”¹ä¸ºï¼šå¹³å‡æåŠå¯†åº¦
        # è¡¡é‡å“ç‰Œåœ¨æ¯æ¬¡å‡ºç°æ—¶çš„å¹³å‡æåŠæ¬¡æ•°ï¼Œåæ˜ è®¨è®ºæ·±åº¦
        mention_density = metrics["total_mentions"] / metrics["mention_in_answers"] if metrics[
                                                                                           "mention_in_answers"] > 0 else 0
        score_ref_depth = (mention_density / max_density) * 100 if max_density > 0 else 0

        # 5. AIè®¤çŸ¥ä»½é¢ (Mind Share) - è¯¥å®ä½“æåŠæ¬¡æ•°å æ‰€æœ‰åŒç±»å®ä½“æ€»æ•°çš„æ¯”ä¾‹
        normalized_mind_share = (metrics[
                                     "total_mentions"] / total_brand_mentions_across_all) if total_brand_mentions_across_all > 0 else 0
        score_mind_share = math.sqrt(normalized_mind_share) * 100

        # 6. ç«äº‰åŠ›æŒ‡æ•° (Competitiveness) - ä½¿ç”¨å‰ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡çš„å¹³å‡åˆ†
        core_scores_avg = (score_visibility + score_mention_rate + score_ai_ranking) / 3
        score_competitiveness = core_scores_avg

        # è®¡ç®—åŠ æƒæ€»åˆ†
        total_score = (
                              score_visibility * weights["visibility"] +
                              score_mention_rate * weights["mention_rate"] +
                              score_ai_ranking * weights["ai_ranking"] +
                              score_ref_depth * weights["ref_depth"] +
                              score_mind_share * weights["mind_share"] +
                              score_competitiveness * weights["competitiveness"]
                      ) / 100 + 10  # é™¤ä»¥100æ˜¯å› ä¸ºæƒé‡æ€»å’Œä¸º100

        final_scores[brand] = {
            "å“ç‰ŒæŒ‡æ•°": total_score,
            "æ€»æåŠæ¬¡æ•°": metrics["total_mentions"],
            "å‡ºç°æ¬¡æ•°": metrics["mention_in_answers"],
            "å¼ºæ¨èæ¬¡æ•°": metrics["strong_recommend_count"],
            "å¹³å‡æåŠå¯†åº¦": mention_density,
            "ç»´åº¦å¾—åˆ†": {
                "visibility": score_visibility,
                "mention_rate": score_mention_rate,
                "ai_ranking": score_ai_ranking,
                "ref_depth": score_ref_depth,
                "mind_share": score_mind_share,
                "competitiveness": score_competitiveness
            }
        }

    return final_scores


def write_ranking_report(output_file: str, title: str, scores: dict, task_name: str):
    """ç”ŸæˆMarkdownæ ¼å¼çš„æ’åæŠ¥å‘Š"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# {title}\n\n")
        f.write(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**åˆ†æä»»åŠ¡**: {task_name}\n\n")
        f.write("---\n\n")

        if not scores:
            f.write("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å“ç‰Œå¾—åˆ†æ•°æ®ã€‚\n\n")
            return

        # æ€»æ¦œå•è¡¨æ ¼
        f.write("## ğŸ“Š å“ç‰Œæ’åæ€»æ¦œå•\n\n")
        f.write(
            "| æ’å | å“ç‰Œåç§° | å“ç‰ŒæŒ‡æ•° | æ€»æåŠæ¬¡æ•° | å‡ºç°æ¬¡æ•° | å¼ºæ¨èæ¬¡æ•° | å“ç‰Œå¯è§åº¦(20) | å¼•ç”¨ç‡(20) | å“ç‰ŒAIè®¤çŸ¥æ’è¡ŒæŒ‡æ•°(20) | æ­£æ–‡å¼•ç”¨ç‡(15) | å“ç‰ŒAIè®¤çŸ¥ä»½é¢(15) | ç«äº‰åŠ›æŒ‡æ•°(10) |\n")
        f.write("|:---:|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n")

        sorted_brands = sorted(scores.items(), key=lambda x: x[1]["å“ç‰ŒæŒ‡æ•°"], reverse=True)

        for rank, (brand, data) in enumerate(sorted_brands, 1):
            dims = data["ç»´åº¦å¾—åˆ†"]

            f.write(
                f"| {rank} | {brand} | **{data['å“ç‰ŒæŒ‡æ•°']:.2f}** | "
                f"{data['æ€»æåŠæ¬¡æ•°']} | {data['å‡ºç°æ¬¡æ•°']} | {data['å¼ºæ¨èæ¬¡æ•°']} | "
                f"{dims['visibility']:.1f} | {dims['mention_rate']:.1f} | {dims['ai_ranking']:.1f} | "
                f"{dims['ref_depth']:.1f} | {dims['mind_share']:.1f} | {dims['competitiveness']:.1f} |\n"
            )

        f.write("\n---\n\n")

        # ç»Ÿè®¡ä¿¡æ¯
        f.write("## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯\n\n")
        f.write(f"- **å‚ä¸æ’åå“ç‰Œæ•°**: {len(scores)}\n")
        f.write(f"- **æœ€é«˜å“ç‰ŒæŒ‡æ•°**: {sorted_brands[0][1]['å“ç‰ŒæŒ‡æ•°']:.2f} ({sorted_brands[0][0]})\n")
        f.write(f"- **å¹³å‡å“ç‰ŒæŒ‡æ•°**: {sum(s['å“ç‰ŒæŒ‡æ•°'] for s in scores.values()) / len(scores):.2f}\n")
        f.write(f"- **æ€»æåŠæ¬¡æ•°**: {sum(s['æ€»æåŠæ¬¡æ•°'] for s in scores.values())}\n")
        f.write("\n")

        # è¯´æ˜
        f.write("## ğŸ“ è¯„åˆ†è¯´æ˜\n\n")
        f.write("æœ¬æ¦œå•é‡‡ç”¨ä¸æµ·å¤–æ¦œå•ç›¸åŒçš„å…­ç»´åº¦è¯„åˆ†ä½“ç³»ï¼š\n\n")
        f.write("1. **å“ç‰Œå¯è§åº¦ (20%)**: å“ç‰Œé¦–æ¬¡å‡ºç°çš„ä½ç½®è¶Šé å‰ï¼Œå¾—åˆ†è¶Šé«˜\n")
        f.write("2. **å¼•ç”¨ç‡ (20%)**: å“ç‰Œè¢«æåŠçš„æ€»æ¬¡æ•°\n")
        f.write("3. **AIè®¤çŸ¥æ’è¡ŒæŒ‡æ•° (20%)**: åŸºäºå¼ºæ¨èæ¬¡æ•°çš„è¯„åˆ†\n")
        f.write("4. **æ­£æ–‡å¼•ç”¨ç‡ (15%)**: å“ç‰Œåœ¨æ¯æ¬¡å‡ºç°æ—¶çš„å¹³å‡æåŠæ¬¡æ•°ï¼Œåæ˜ è®¨è®ºæ·±åº¦\n")
        f.write("5. **AIè®¤çŸ¥ä»½é¢ (15%)**: å“ç‰ŒæåŠæ¬¡æ•°å æ‰€æœ‰å“ç‰Œæ€»æ•°çš„æ¯”ä¾‹\n")
        f.write("6. **ç«äº‰åŠ›æŒ‡æ•° (10%)**: å‰ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡çš„ç»¼åˆè¯„åˆ†\n")
        f.write("\n")


def main():
    parser = argparse.ArgumentParser(description="å›½å†…æ¦œå•åˆ†æå¼•æ“")
    parser.add_argument("--task", required=True, help="ä»»åŠ¡åç§° (ä¾‹å¦‚: nev, scenic)")
    parser.add_argument("--results", required=True, help="ç»“æœæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: results_nev_merged.json)")
    parser.add_argument("--brands", required=True, help="å“ç‰Œè¯å…¸æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: brand_dictionary_nev.yaml)")
    parser.add_argument("--output", default=None, help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ranking_report_{task}.md)")
    args = parser.parse_args()

    # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if args.output is None:
        args.output = f"ranking_report_{args.task}.md"

    print(f"\n{'=' * 60}")
    print(f"å›½å†…æ¦œå•åˆ†æå¼•æ“")
    print(f"{'=' * 60}\n")
    print(f"ğŸ“‹ ä»»åŠ¡åç§°: {args.task}")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶: {args.results}")
    print(f"ğŸ“– å“ç‰Œè¯å…¸: {args.brands}")
    print(f"ğŸ“„ è¾“å‡ºæŠ¥å‘Š: {args.output}\n")

    # åŠ è½½å“ç‰Œè¯å…¸
    print("æ­£åœ¨åŠ è½½å“ç‰Œè¯å…¸...")
    try:
        with open(args.brands, 'r', encoding='utf-8') as f:
            brands_config = yaml.safe_load(f)
        brand_dictionary = brands_config['brand_dictionary']
        brands_whitelist = set(brands_config['brands_whitelist'])
        print(f"âœ… æˆåŠŸåŠ è½½ {len(brand_dictionary)} ä¸ªå“ç‰Œï¼Œç™½åå•åŒ…å« {len(brands_whitelist)} ä¸ªå“ç‰Œ\n")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: å“ç‰Œè¯å…¸æ–‡ä»¶ '{args.brands}' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½å“ç‰Œè¯å…¸æ—¶å‡ºé”™: {e}")
        return

    # åŠ è½½ç»“æœæ•°æ®
    print("æ­£åœ¨åŠ è½½ç»“æœæ•°æ®...")
    try:
        with open(args.results, 'r', encoding='utf-8') as f:
            data_list = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(data_list)} æ¡å›ç­”è®°å½•\n")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: ç»“æœæ–‡ä»¶ '{args.results}' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½ç»“æœæ•°æ®æ—¶å‡ºé”™: {e}")
        return

    # å®šä¹‰æƒé‡ï¼ˆä¸æµ·å¤–æ¦œå•å®Œå…¨ä¸€è‡´ï¼‰
    weights = {
        "visibility": 20,
        "mention_rate": 20,
        "ai_ranking": 20,
        "ref_depth": 15,
        "mind_share": 15,
        "competitiveness": 10
    }

    # è®¡ç®—å¾—åˆ†
    print("æ­£åœ¨è®¡ç®—å“ç‰Œå¾—åˆ†...")
    scores = calculate_scores(data_list, brand_dictionary, brands_whitelist, weights)
    print(f"âœ… æˆåŠŸè®¡ç®— {len(scores)} ä¸ªå“ç‰Œçš„å¾—åˆ†\n")

    # ç”ŸæˆæŠ¥å‘Š
    print("æ­£åœ¨ç”Ÿæˆæ’åæŠ¥å‘Š...")
    report_title = f"{args.task.upper()} å“ç‰ŒGenAIè®¤çŸ¥æŒ‡æ•°æ’è¡Œæ¦œ"
    write_ranking_report(args.output, report_title, scores, args.task)
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}\n")

    # æ˜¾ç¤ºå‰10å
    if scores:
        print("ğŸ† Top 10 å“ç‰Œé¢„è§ˆ:")
        print("-" * 60)
        sorted_brands = sorted(scores.items(), key=lambda x: x[1]["å“ç‰ŒæŒ‡æ•°"], reverse=True)
        for rank, (brand, data) in enumerate(sorted_brands[:10], 1):
            print(f"  {rank:2d}. {brand:15s} - å“ç‰ŒæŒ‡æ•°: {data['å“ç‰ŒæŒ‡æ•°']:6.2f}")
        print("-" * 60)

    print(f"\n{'=' * 60}")
    print("åˆ†æå®Œæˆï¼")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
