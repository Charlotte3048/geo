import openai
import json
import os
import re
import argparse
from collections import Counter
import time
import glob
from dotenv import load_dotenv

# ==============================================================================
# å“ç‰Œæ¢ç´¢å¼•æ“ : ä» AI å›ç­”ä¸­æå–å“ç‰Œåç§°ï¼Œç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿
# ==============================================================================
# ç¤ºä¾‹ç”¨æ³•:
# è¯·ç¡®è®¤åœ¨overseaç›®å½•ä¸‹è¿è¡Œï¼Œè‹¥ä¸åœ¨overseaç›®å½•ä¸‹ï¼Œè¯·å…ˆåœ¨æ§åˆ¶å°ä¸­è¿è¡Œå¦‚ä¸‹å‘½ä»¤åˆ‡æ¢ç›®å½•ï¼š
# cd oversea
# python explore_brand_oversea.py --task ha --category_prefix "å®¶ç”¨ç”µå™¨"
# python explore_brand_oversea.py --task sh --category_prefix "æ™ºèƒ½ç¡¬ä»¶"
# python explore_brand_oversea.py --task ha --category_prefix "å®¶ç”¨ç”µå™¨" --results_file results/results_merged_ha_20260114.json
# ==============================================================================

# å‡è®¾æ‚¨çš„é¡¹ç›®æ ¹ç›®å½•æ˜¯ oversea
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# åŠ è½½ .env æ–‡ä»¶ï¼ˆä»æ ¹ç›®å½•åŠ è½½ï¼‰
root_dir = os.path.dirname(BASE_DIR)  # è·å–çˆ¶ç›®å½•ï¼ˆæ ¹ç›®å½•ï¼‰
load_dotenv(os.path.join(root_dir, '.env'))

# é»˜è®¤æ¨¡å‹
DEFAULT_MODEL = "google/gemini-2.5-flash"

# é¢„è®¾çš„å“ç±» Prompt æ¨¡æ¿
CATEGORY_PROMPTS = {
    "ha": """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„æ–‡æœ¬ä¸­ï¼Œæå–æ‰€æœ‰æ¸…æ™°çš„å®¶ç”¨ç”µå™¨å“ç‰Œåç§°ã€‚
è§„åˆ™:
1. åªè¿”å›å®¶ç”¨ç”µå™¨å“ç‰Œåç§°ï¼Œä¾‹å¦‚: "Midea", "Haier", "Samsung", "LG", "Sony", "Panasonic"ã€‚
2. åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å“ç±»çš„å“ç‰Œ: ç”µè§†ã€å†°ç®±ã€æ´—è¡£æœºã€ç©ºè°ƒã€å¨æˆ¿ç”µå™¨ã€æ¸…æ´ç”µå™¨ã€éŸ³é¢‘è®¾å¤‡ç­‰ã€‚
3. å¿½ç•¥éå“ç‰Œçš„é€šç”¨è¯æ±‡ï¼Œä¾‹å¦‚: "ç”µè§†æœº", "å†°ç®±", "ç©ºè°ƒ", "æ™ºèƒ½å®¶å±…" ç­‰å“ç±»åç§°ã€‚
4. å¿½ç•¥é›¶å”®å•†/å¹³å°åç§°ï¼Œä¾‹å¦‚: "Amazon", "Best Buy", "äº¬ä¸œ", "å¤©çŒ«"ã€‚
5. åŒæ—¶è¯†åˆ«ä¸­è‹±æ–‡å“ç‰Œåç§°ï¼Œä¾‹å¦‚: "ç¾çš„" å’Œ "Midea" éƒ½åº”è¯¥æå–ã€‚
6. è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼ä¸º: {"brands": ["Brand1", "Brand2", ...]}ï¼›å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å“ç‰Œï¼Œè¿”å› {"brands": []}ã€‚
""",
    "sh": """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¸‚åœºåˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„æ–‡æœ¬ä¸­ï¼Œæå–æ‰€æœ‰æ¸…æ™°çš„æ™ºèƒ½ç¡¬ä»¶å“ç‰Œåç§°ã€‚
è§„åˆ™:
1. åªè¿”å›æ™ºèƒ½ç¡¬ä»¶å“ç‰Œåç§°ï¼Œä¾‹å¦‚: "DJI", "Huawei", "Xiaomi", "Anker", "Roborock"ã€‚
2. åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å“ç±»çš„å“ç‰Œ: æ— äººæœºã€æ™ºèƒ½æ‰‹è¡¨ã€æ™ºèƒ½éŸ³ç®±ã€æ‰«åœ°æœºå™¨äººã€å……ç”µè®¾å¤‡ã€3Dæ‰“å°æœºã€ä¾¿æºå‚¨èƒ½ç­‰ã€‚
3. å¿½ç•¥éå“ç‰Œçš„é€šç”¨è¯æ±‡ï¼Œä¾‹å¦‚: "æ— äººæœº", "æ™ºèƒ½æ‰‹è¡¨", "æ‰«åœ°æœºå™¨äºº" ç­‰å“ç±»åç§°ã€‚
4. å¿½ç•¥é›¶å”®å•†/å¹³å°åç§°ï¼Œä¾‹å¦‚: "Amazon", "Best Buy", "äº¬ä¸œ", "å¤©çŒ«"ã€‚
5. åŒæ—¶è¯†åˆ«ä¸­è‹±æ–‡å“ç‰Œåç§°ï¼Œä¾‹å¦‚: "å¤§ç–†" å’Œ "DJI" éƒ½åº”è¯¥æå–ã€‚
6. è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼ä¸º: {"brands": ["Brand1", "Brand2", ...]}ï¼›å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å“ç‰Œï¼Œè¿”å› {"brands": []}ã€‚
"""
}

# å“ç±»åç§°æ˜ å°„
CATEGORY_NAMES = {
    "ha": "Home Appliance",
    "sh": "Smart Hardware"
}


def find_latest_results_file(task: str) -> str:
    """æŸ¥æ‰¾æŒ‡å®šä»»åŠ¡çš„æœ€æ–°ç»“æœæ–‡ä»¶"""
    results_dir = os.path.join(BASE_DIR, "results")
    pattern = os.path.join(results_dir, f"results_merged_{task}_*.json")
    files = glob.glob(pattern)

    if not files:
        return None

    # æŒ‰æ–‡ä»¶åæ’åºï¼ˆæ—¥æœŸæˆ³åœ¨æ–‡ä»¶åä¸­ï¼‰ï¼Œå–æœ€æ–°çš„
    files.sort(reverse=True)
    return files[0]


def get_brands_from_text_with_ai(client: openai.OpenAI, text: str, model: str, system_prompt: str) -> list:
    """ä½¿ç”¨æŒ‡å®šçš„AIæ¨¡å‹ä»æ–‡æœ¬ä¸­æå–å“ç‰Œåç§°"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ],
            temperature=0.0,
            response_format={"type": "json_object"},
        )
        content = json.loads(response.choices[0].message.content)
        if isinstance(content, dict):
            return content.get("brands", [])
        elif isinstance(content, list):
            return content
        return []
    except Exception as e:
        print(f"  - AI extraction error: {e}")
        return []


def generate_config_template(config_file_path: str, task_name: str, brand_counts: Counter, results_file: str):
    """æ ¹æ®å“ç‰Œåˆ—è¡¨ï¼Œç”Ÿæˆä¸€ä¸ªå¸¦æ³¨é‡Šçš„YAMLé…ç½®æ–‡ä»¶æ¨¡æ¿"""
    category_name = CATEGORY_NAMES.get(task_name, task_name.replace('_', ' ').title())

    with open(config_file_path, 'w', encoding='utf-8') as f:
        f.write(f"# {category_name} å“ç±»åˆ†æé…ç½®æ–‡ä»¶\n")
        f.write("# ========================================================\n")
        f.write(f"# è‡ªåŠ¨ç”Ÿæˆäº: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("# è¯·ä»”ç»†å®¡æ ¸å’Œå®Œå–„æ­¤æ–‡ä»¶ï¼Œç‰¹åˆ«æ˜¯ brand_dictionary å’Œ brands_whitelistã€‚\n\n")

        f.write(f"task_name: {task_name}\n")
        f.write(f"results_file: {results_file}\n")
        f.write(f"ranking_output_file: ranking_report_{task_name}.md\n")
        f.write(f"report_title: '# ä¸­å›½å‡ºæµ·å“ç‰ŒAIè®¤çŸ¥æŒ‡æ•° -- {category_name}ç±»'\n\n")

        # æ·»åŠ æƒé‡é…ç½®
        f.write("weights:\n")
        f.write("  brand_prominence: 20\n")
        f.write("  share_of_voice: 20\n")
        f.write("  top10_visibility: 20\n")
        f.write("  competitiveness: 20\n")
        f.write("  sentiment_analysis: 20\n\n")

        f.write("\n# æ­¥éª¤ä¸€: å®Œå–„å“ç‰Œè¯å…¸ (åŒ…å«æ‰€æœ‰ä¸­å¤–å“ç‰ŒåŠå…¶åˆ«å)\n")
        f.write("brand_dictionary:\n")
        for brand, count in brand_counts.most_common():
            # ä¸ºé«˜é¢‘è¯è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªåŸºç¡€æ¨¡æ¿
            if count > 1:
                # æ ‡å‡†åŒ–å“ç‰Œåç§°ï¼ˆé¦–å­—æ¯å¤§å†™ï¼Œå»é™¤ç©ºæ ¼ï¼‰
                std_name = brand.strip().title().replace(' ', '')
                f.write(f"  {std_name}: [{brand.lower()}] # ({count}æ¬¡)\n")
        f.write("\n  # --- è¯·åœ¨æ­¤å¤„æ‰‹åŠ¨æ·»åŠ æˆ–åˆå¹¶åˆ«å ---\n")
        f.write("  # Example: Anker: [anker, anker innovations, å®‰å…‹]\n\n")

        f.write("# æ­¥éª¤äºŒ: å®šä¹‰ä¸­å›½å“ç‰Œç™½åå• (ä»…ä½¿ç”¨æ ‡å‡†é”®å)\n")
        f.write("brands_whitelist:\n")
        for brand, count in brand_counts.most_common():
            if count > 1:
                std_name = brand.strip().title().replace(' ', '')
                f.write(f"  - {std_name}\n")
        f.write("\n  # --- è¯·åœ¨æ­¤å¤„å®¡æ ¸ï¼Œåªä¿ç•™ä¸­å›½å“ç‰Œ ---\n")

    print(f"\nâœ… é…ç½®æ–‡ä»¶æ¨¡æ¿å·²ç”Ÿæˆ: '{config_file_path}'")
    print("ä¸‹ä¸€æ­¥å…³é”®æ“ä½œï¼šè¯·æ‰“å¼€å¹¶ç¼–è¾‘æ­¤YAMLæ–‡ä»¶ï¼Œå®Œæˆå“ç‰Œè¯å…¸å’Œç™½åå•çš„æœ€ç»ˆç¡®è®¤ï¼")


def main():
    # --- 1. å‘½ä»¤è¡Œå‚æ•°è§£æ ---
    parser = argparse.ArgumentParser(description="å“ç‰Œæ¢ç´¢å¼•æ“ (v5.0)")
    parser.add_argument("--task", required=True, choices=["ha", "sh"],
                        help="ä»»åŠ¡åç§°: ha (å®¶ç”¨ç”µå™¨) æˆ– sh (æ™ºèƒ½ç¡¬ä»¶)")
    parser.add_argument("--category_prefix", required=True,
                        help="ç”¨äºç­›é€‰æ•°æ®çš„åˆ†ç±»åå‰ç¼€ (ä¾‹å¦‚: 'å®¶ç”¨ç”µå™¨' æˆ– 'æ™ºèƒ½ç¡¬ä»¶')")
    parser.add_argument("--results_file", default=None,
                        help="ç»“æœæ–‡ä»¶è·¯å¾„ (é»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾ results/ ç›®å½•ä¸‹æœ€æ–°çš„æ–‡ä»¶)")
    parser.add_argument("--model", default=DEFAULT_MODEL,
                        help="ç”¨äºå“ç‰Œæå–çš„LLMæ¨¡å‹ID")
    args = parser.parse_args()

    print(f"\n{'=' * 60}")
    print(f"å“ç‰Œæ¢ç´¢å¼•æ“ (v5.0)")
    print(f"{'=' * 60}\n")

    # --- 2. è®¾ç½®APIå®¢æˆ·ç«¯ ---
    api_key = os.environ.get("OPENROUTER_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ 'OPENROUTER_API_KEY'ã€‚")
        return
    client = openai.OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

    # --- 3. ç¡®å®šç»“æœæ–‡ä»¶è·¯å¾„ ---
    if args.results_file:
        results_file = args.results_file
    else:
        results_file = find_latest_results_file(args.task)
        if not results_file:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡ '{args.task}' çš„ç»“æœæ–‡ä»¶ã€‚")
            print(f"   è¯·ç¡®ä¿ results/ ç›®å½•ä¸‹å­˜åœ¨ results_merged_{args.task}_*.json æ–‡ä»¶ï¼Œ")
            print(f"   æˆ–ä½¿ç”¨ --results_file å‚æ•°æŒ‡å®šæ–‡ä»¶è·¯å¾„ã€‚")
            return

    # --- 4. è·å–å“ç±»å¯¹åº”çš„ Prompt ---
    system_prompt = CATEGORY_PROMPTS.get(args.task)
    if not system_prompt:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡ '{args.task}' çš„ Prompt æ¨¡æ¿ã€‚")
        return

    category_name = CATEGORY_NAMES.get(args.task, args.task)

    print(f"ğŸ“‹ ä»»åŠ¡: {args.task} ({category_name})")
    print(f"ğŸ“‚ åˆ†ç±»å‰ç¼€: {args.category_prefix}")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {results_file}")
    print(f"ğŸ¤– æ¨¡å‹: {args.model}\n")

    # --- 5. åŠ è½½å¹¶ç­›é€‰æ•°æ® ---
    print(f"æ­£åœ¨åŠ è½½æ•°æ®...")
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            all_data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶ '{results_file}' æœªæ‰¾åˆ°ã€‚")
        return

    filtered_data = [item for item in all_data if item.get('category', '').startswith(args.category_prefix)]

    if not filtered_data:
        print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•åˆ†ç±»ä»¥ '{args.category_prefix}' å¼€å¤´çš„æ¡ç›®ã€‚")
        print(f"   è¯·æ£€æŸ¥å‰ç¼€æ˜¯å¦æ­£ç¡®ã€‚")
        return

    all_answers = [item['response']['answer'] for item in filtered_data if
                   'response' in item and 'answer' in item['response']]
    print(f"âœ… ç­›é€‰å®Œæˆï¼å…±æ‰¾åˆ° {len(all_answers)} æ¡ç›¸å…³å›ç­”è¿›è¡Œåˆ†æã€‚\n")

    # --- 6. æ™ºèƒ½å“ç‰Œæå– ---
    print(f"{'â”€' * 50}")
    print(f"å¼€å§‹æ™ºèƒ½å“ç‰Œæå–...")
    print(f"{'â”€' * 50}")

    all_extracted_brands = []
    for i, answer in enumerate(all_answers):
        print(f"  [{i + 1}/{len(all_answers)}] æ­£åœ¨å¤„ç†...")
        brands = get_brands_from_text_with_ai(client, answer, args.model, system_prompt)
        if brands:
            all_extracted_brands.extend(brands)
            print(f"      æå–åˆ° {len(brands)} ä¸ªå“ç‰Œ")
        else:
            print(f"      æœªæå–åˆ°å“ç‰Œ")
        time.sleep(0.5)  # è½»å¾®å»¶è¿Ÿä»¥ç¤ºå‹å¥½

    brand_counts = Counter(all_extracted_brands)
    print(f"\nâœ… æå–å®Œæˆï¼å…±å‘ç° {len(brand_counts)} ä¸ªç‹¬ç‰¹çš„å€™é€‰å“ç‰Œã€‚\n")

    # --- 7. ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿ (ä¿å­˜åˆ° config ç›®å½•) ---
    config_dir = os.path.join(BASE_DIR, "config")
    os.makedirs(config_dir, exist_ok=True)

    config_template_file = os.path.join(config_dir, f"config_{args.task}.yaml")

    # ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿
    generate_config_template(config_template_file, args.task, brand_counts, results_file)

    # --- 8. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ ---
    print(f"\n{'=' * 60}")
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - åˆ†æå›ç­”æ•°: {len(all_answers)}")
    print(f"   - æå–å“ç‰Œæ€»æ•°: {len(all_extracted_brands)}")
    print(f"   - ç‹¬ç‰¹å“ç‰Œæ•°: {len(brand_counts)}")
    print(f"   - é…ç½®æ¨¡æ¿æ–‡ä»¶: {config_template_file}")

    # æ˜¾ç¤º Top 10 å“ç‰Œ
    print(f"\nğŸ† Top 10 é«˜é¢‘å“ç‰Œ:")
    print(f"{'â”€' * 40}")
    for i, (brand, count) in enumerate(brand_counts.most_common(10), 1):
        print(f"   {i:2d}. {brand:20s} ({count}æ¬¡)")

    print(f"\n{'=' * 60}")
    print("âœ… å“ç‰Œæ¢ç´¢å®Œæˆï¼")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
