import openai
import json
import os
import time
import argparse
import yaml
import re
from dotenv import load_dotenv

# ==============================================================================
# æµ·å¤–æ•°æ®é‡‡é›†å¼•æ“ (v2.0 - å“ç±»é©±åŠ¨ç‰ˆ)
# æè¿°: æŒ‰å“ç±»è¿è¡Œï¼Œæ”¯æŒæŒ‡å®šå•ä¸ªæ¨¡å‹æˆ–è¿è¡Œæ‰€æœ‰æ¨¡å‹ï¼Œç›´æ¥è¾“å‡ºåˆå¹¶ç»“æœæ–‡ä»¶ï¼ˆå¸¦æ—¥æœŸæˆ³ï¼‰
# ==============================================================================
# ç¤ºä¾‹ç”¨æ³•:
# python run_analysis_oversea.py --task ha                    # è¿è¡Œå®¶ç”¨ç”µå™¨å“ç±»çš„æ‰€æœ‰æ¨¡å‹
# python run_analysis_oversea.py --task ha --model gemini     # åªè¿è¡Œå®¶ç”¨ç”µå™¨å“ç±»çš„ gemini æ¨¡å‹
# python run_analysis_oversea.py --task sh --model perplexity # åªè¿è¡Œæ™ºèƒ½ç¡¬ä»¶å“ç±»çš„ perplexity æ¨¡å‹
# ==============================================================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# åŠ è½½ .env æ–‡ä»¶ï¼ˆä»æ ¹ç›®å½•åŠ è½½ï¼‰
root_dir = os.path.dirname(BASE_DIR)  # è·å–çˆ¶ç›®å½•ï¼ˆæ ¹ç›®å½•ï¼‰
load_dotenv(os.path.join(root_dir, '.env'))



def load_config(config_path):
    """åŠ è½½ YAML é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def load_questions(questions_path):
    """åŠ è½½é—®é¢˜ JSON æ–‡ä»¶"""
    with open(questions_path, 'r', encoding='utf-8') as f:
        return json.load(f)


# ------------ GPT / Gemini è”ç½‘æœç´¢è°ƒç”¨ï¼ˆé€šè¿‡ OpenRouter :online åç¼€ï¼‰ ---------------- #
def get_online_response(client, question: str, model: str, model_key: str, retries=3, delay=10):
    """
    é€šè¿‡ OpenRouter è°ƒç”¨ GPT / Gemini æ¨¡å‹ï¼ˆä½¿ç”¨ :online åç¼€å¯ç”¨è”ç½‘æœç´¢ï¼‰
    """
    URL_PATTERN = r'https?://[^\s )>\]]+'

    # æ·»åŠ  :online åç¼€ä»¥å¯ç”¨è”ç½‘æœç´¢
    if not model.endswith(':online'):
        model = f"{model}:online"

    for attempt in range(retries):
        try:
            print(f"      æ­£åœ¨è°ƒç”¨ {model_key.upper()} æ¨¡å‹ '{model}' (å°è¯• {attempt + 1}/{retries})...")

            completion = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": question}],
                temperature=0.1,
            )

            answer = completion.choices[0].message.content or ""

            # æå– URL ä½œä¸ºå¼•ç”¨
            references = []
            urls = re.findall(URL_PATTERN, answer)
            seen_urls = set()

            for url in urls:
                clean_url = url.strip().rstrip(".,;:)]")
                if clean_url and clean_url not in seen_urls:
                    seen_urls.add(clean_url)
                    references.append({
                        "url": clean_url,
                        "title": "",
                        "publisher": "",
                        "snippet": "",
                    })

            return {"answer": answer, "references": references}

        except Exception as e:
            error_msg = str(e)
            print(f"      {model_key.upper()} è°ƒç”¨é”™è¯¯: {error_msg}")

            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
                wait_time = delay * (attempt + 1)
                print(f"      é…é¢é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            elif attempt < retries - 1:
                print(f"      ç­‰å¾… {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                print("      æ‰€æœ‰é‡è¯•å‡å¤±è´¥ã€‚")
                return {"answer": "", "references": []}

    return {"answer": "", "references": []}


# ------------ Perplexity åŸç”Ÿè”ç½‘æœç´¢è°ƒç”¨ï¼ˆä¸éœ€è¦ :online åç¼€ï¼‰ ---------------- #
def get_perplexity_response(client, question: str, model: str, retries=3, delay=5):
    """
    è°ƒç”¨ Perplexity æ¨¡å‹ï¼ˆåŸç”Ÿæ”¯æŒè”ç½‘æœç´¢ï¼Œä¸éœ€è¦ :online åç¼€ï¼‰
    """
    URL_PATTERN = r'https?://[^\s)>\]]+'

    for attempt in range(retries):
        try:
            print(f"      æ­£åœ¨è°ƒç”¨ PERPLEXITY æ¨¡å‹ '{model}' (å°è¯• {attempt + 1}/{retries})...")
            completion = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": question}],
                temperature=0.1,
            )

            response_content = completion.choices[0].message.content or ""

            # æ­£åˆ™ URL æŠ“å–
            urls = re.findall(URL_PATTERN, response_content)
            seen_urls = set()
            references = []

            for url in urls:
                clean_url = url.strip().rstrip(".,;:)]")
                if clean_url and clean_url not in seen_urls:
                    seen_urls.add(clean_url)
                    references.append({
                        "url": clean_url,
                        "title": "",
                        "publisher": "",
                        "snippet": "",
                    })

            return {"answer": response_content, "references": references}

        except Exception as e:
            error_msg = str(e)
            print(f"      PERPLEXITY è°ƒç”¨é”™è¯¯: {error_msg}")

            if "429" in error_msg:
                wait_time = delay * (attempt + 1)
                print(f"      é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            elif attempt < retries - 1:
                print(f"      ç­‰å¾… {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                print("      æ‰€æœ‰é‡è¯•å‡å¤±è´¥ã€‚")
                return {"answer": "", "references": []}

    return {"answer": "", "references": []}


def call_model(client, model_key: str, model_name: str, question: str):
    """
    æ ¹æ®æ¨¡å‹ key åˆ†æ´¾åˆ°ä¸åŒçš„ API è°ƒç”¨å‡½æ•°
    - GPT / Gemini: ä½¿ç”¨ :online åç¼€å¯ç”¨è”ç½‘æœç´¢
    - Perplexity: åŸç”Ÿè”ç½‘æœç´¢ï¼Œä¸éœ€è¦åç¼€
    """
    try:
        if "perplexity" in model_key.lower():
            # Perplexity åŸç”Ÿè”ç½‘æœç´¢
            return get_perplexity_response(client, question, model_name)
        else:
            # GPT / Gemini ä½¿ç”¨ :online åç¼€
            return get_online_response(client, question, model_name, model_key)
    except Exception as e:
        print(f"      FATAL ERROR for {model_key}: {e}")
        return {"answer": "", "references": []}


def main():
    parser = argparse.ArgumentParser(description="æµ·å¤–æ•°æ®é‡‡é›†å¼•æ“")
    parser.add_argument("--task", required=True, help="ä»»åŠ¡/å“ç±»åç§° (å¦‚: ha, sh)")
    parser.add_argument("--model", default=None, help="æŒ‡å®šå•ä¸ªæ¨¡å‹ (å¦‚: gemini, gpt, perplexity)ï¼Œä¸æŒ‡å®šåˆ™è¿è¡Œæ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--config", default="config_oversea.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    print(f"\n{'=' * 60}")
    print(f"æµ·å¤–æ•°æ®é‡‡é›†å¼•æ“")
    print(f"{'=' * 60}\n")

    # åŠ è½½ .env æ–‡ä»¶
    load_dotenv(os.path.join(BASE_DIR, '.env'))

    # è¯»å–é…ç½®æ–‡ä»¶
    config_path = os.path.join(BASE_DIR, args.config)
    if not os.path.exists(config_path):
        print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ '{config_path}' æœªæ‰¾åˆ°ã€‚")
        return

    config = load_config(config_path)

    # è·å–ä»»åŠ¡é…ç½®
    task_cfg = config.get('tasks', {}).get(args.task)
    if not task_cfg:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡ '{args.task}' çš„é…ç½®ã€‚")
        print(f"   å¯ç”¨ä»»åŠ¡: {', '.join(config.get('tasks', {}).keys())}")
        return

    task_name = task_cfg.get("name", args.task)
    category_prefix = task_cfg.get("category_prefix", "")
    questions_file = task_cfg.get("questions_file", f"question/questions_{args.task}.json")

    # è·å–æ¨¡å‹é…ç½®
    all_models = config.get("models", {})
    if args.model:
        # æŒ‡å®šäº†å•ä¸ªæ¨¡å‹
        if args.model not in all_models:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹ '{args.model}' çš„é…ç½®ã€‚")
            print(f"   å¯ç”¨æ¨¡å‹: {', '.join(all_models.keys())}")
            return
        models_to_run = {args.model: all_models[args.model]}
    else:
        # è¿è¡Œæ‰€æœ‰æ¨¡å‹
        models_to_run = all_models

    print(f"ğŸ“‹ ä»»åŠ¡: {task_name} ({args.task})")
    print(f"ğŸ“‚ å“ç±»å‰ç¼€: {category_prefix}")
    print(f"ğŸ“„ é—®é¢˜æ–‡ä»¶: {questions_file}")
    print(f"ğŸ¤– æ¨¡å‹: {', '.join(models_to_run.keys())}")
    print(f"   - GPT/Gemini: ä½¿ç”¨ :online åç¼€å¯ç”¨è”ç½‘æœç´¢")
    print(f"   - Perplexity: åŸç”Ÿè”ç½‘æœç´¢\n")

    # åˆå§‹åŒ– OpenRouter å®¢æˆ·ç«¯
    api_key = os.environ.get("OPENROUTER_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: è¯·å…ˆè®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        return

    client = openai.OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

    # åŠ è½½é—®é¢˜æ–‡ä»¶
    questions_path = os.path.join(BASE_DIR, questions_file)
    if not os.path.exists(questions_path):
        print(f"âŒ é”™è¯¯: é—®é¢˜æ–‡ä»¶ '{questions_path}' æœªæ‰¾åˆ°ã€‚")
        return

    all_questions = load_questions(questions_path)

    # æŒ‰å“ç±»å‰ç¼€ç­›é€‰é—®é¢˜
    if category_prefix:
        questions_to_run = [q for q in all_questions if q.get('category', '').startswith(category_prefix)]
    else:
        questions_to_run = all_questions

    print(f"ğŸ“ åŒ¹é…åˆ° {len(questions_to_run)} ä¸ªé—®é¢˜\n")

    if not questions_to_run:
        print("âš ï¸ æ²¡æœ‰åŒ¹é…çš„é—®é¢˜ï¼Œé€€å‡ºã€‚")
        return

    # å‡†å¤‡è¾“å‡ºæ–‡ä»¶ï¼ˆå¸¦æ—¥æœŸæˆ³ï¼Œä¿å­˜åˆ° results ç›®å½•ï¼‰
    current_date = time.strftime("%Y%m%d")
    results_dir = os.path.join(BASE_DIR, "results")
    os.makedirs(results_dir, exist_ok=True)
    output_file = os.path.join(results_dir, f"results_merged_{args.task}_{current_date}.json")

    # åŠ è½½å·²æœ‰ç»“æœï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    all_results = []
    processed_keys = set()  # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„ (question_id, model) ç»„åˆ

    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                all_results = json.load(f)
                for item in all_results:
                    key = (item.get("id"), item.get("ai_model"))
                    processed_keys.add(key)
                print(f"ğŸ“‚ å·²åŠ è½½ {len(all_results)} æ¡å†å²è®°å½•ï¼ˆæ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼‰\n")
        except json.JSONDecodeError:
            print("âš ï¸ è¾“å‡ºæ–‡ä»¶æŸåï¼Œå°†é‡æ–°ç”Ÿæˆ\n")
            all_results = []

    # å¼€å§‹é‡‡é›†
    total_questions = len(questions_to_run)
    total_models = len(models_to_run)
    total_tasks = total_questions * total_models
    completed = 0

    for model_key, model_name in models_to_run.items():
        print(f"\n{'â”€' * 50}")
        print(f"ğŸ¤– å¼€å§‹é‡‡é›†æ¨¡å‹: {model_key} ({model_name})")
        if "perplexity" in model_key.lower():
            print(f"   ğŸ“¡ æ¨¡å¼: åŸç”Ÿè”ç½‘æœç´¢")
        else:
            print(f"   ğŸ“¡ æ¨¡å¼: :online åç¼€è”ç½‘æœç´¢")
        print(f"{'â”€' * 50}")

        for idx, question in enumerate(questions_to_run):
            q_id = question.get("id")
            q_text = question.get("question", question.get("prompt", ""))
            q_category = question.get("category", "")

            completed += 1
            progress = f"[{completed}/{total_tasks}]"

            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if (q_id, model_name) in processed_keys:
                print(f"  {progress} Q{q_id}: å·²å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            print(f"  {progress} Q{q_id} ({q_category}): {q_text[:50]}...")

            # è°ƒç”¨æ¨¡å‹
            response = call_model(client, model_key, model_name, q_text)

            # æ„é€ ç»“æœ
            result = {
                "id": q_id,
                "category": q_category,
                "question": q_text,
                "ai_model": model_name,
                "model_key": model_key,
                "task": args.task,
                "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
                "response": response
            }

            all_results.append(result)
            processed_keys.add((q_id, model_name))

            # å®æ—¶ä¿å­˜
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, ensure_ascii=False, indent=2)

            print(f"      âœ… å·²ä¿å­˜")

    # æ±‡æ€»å¼•ç”¨
    print(f"\n{'=' * 60}")
    print("ğŸ“Š é‡‡é›†å®Œæˆï¼Œæ±‡æ€»å¼•ç”¨...")

    all_refs = []
    seen_urls = set()

    for item in all_results:
        refs = item.get("response", {}).get("references", [])
        for r in refs:
            url = r.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                all_refs.append(r)

    refs_dir = os.path.join(BASE_DIR, "references")
    os.makedirs(refs_dir, exist_ok=True)
    refs_file = os.path.join(refs_dir, f"references_{args.task}_{current_date}.json")
    with open(refs_file, "w", encoding="utf-8") as f:
        json.dump(all_refs, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€»ç»“æœæ•°: {len(all_results)}")
    print(f"   - æ€»å¼•ç”¨æ•°: {len(all_refs)}")
    print(f"   - ç»“æœæ–‡ä»¶: {output_file}")
    print(f"   - å¼•ç”¨æ–‡ä»¶: {refs_file}")

    print(f"\n{'=' * 60}")
    print("âœ… å…¨éƒ¨é‡‡é›†ä»»åŠ¡å®Œæˆï¼")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
