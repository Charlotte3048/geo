# 模型训练与微调说明（train.md）

## 1. 训练目标

本阶段训练的目标是：
在冻结预训练模型主体参数的前提下，使用 **LoRA（Low-Rank Adaptation）** 对模型进行参数高效微调，使其能够完成 **基于 Yelp
评论的五级情感强度分类任务**，并验证一套 **可复现、可部署、工程友好** 的训练流程。

本项目的关注重点不在于极致性能优化，而在于：

* 验证 LoRA 在复杂多分类情感任务中的有效性
* 构建稳定、可复现的训练流程
* 产出可独立版本化、可部署的模型适配器（adapter）
* 为后续推理、Agent 调用和服务化部署打下基础

---

## 2. 任务建模方式

### 2.1 情感任务定义

本项目将 Yelp Review 的 1–5 星评分建模为 **五级情感强度分类任务**：

| 类别索引 | 情感含义                  |
|------|-----------------------|
| 0    | 强烈负面（Strong Negative） |
| 1    | 负面（Negative）          |
| 2    | 中立（Neutral）           |
| 3    | 正面（Positive）          |
| 4    | 强烈正面（Strong Positive） |

### 2.2 为什么不采用二分类？

虽然二分类情感分析在学术与工业实践中较为常见，但在真实业务场景中：

- “差评”与“极差评”往往具有不同的处理优先级
- “好评”与“强烈推荐”在商业价值上存在显著差异
- 原始评分本身天然包含情感强度与序信息

因此，本项目选择保留评分中的情感强度信息，采用多分类建模方式，以更贴近真实用户反馈分布。

---

## 3. 基础模型选择

基础模型：bert-base-uncased

选择原因：

- 具备稳定、通用的语言表示能力
- 架构成熟，社区支持完善
- 在性能与计算成本之间取得良好平衡
- 与 LoRA / PEFT 框架高度兼容
- 适合后续推理与部署

---

## 4. 微调方法：LoRA（Low-Rank Adaptation）

### 4.1 采用 LoRA 的原因

本项目采用 LoRA 进行微调，核心原因包括：

- 冻结基础模型全部参数，仅训练低秩适配器
- 可训练参数比例显著降低（< 0.3%）
- 显著减少显存占用与训练成本
- 训练稳定、易于复现
- 训练产物可作为独立 adapter 进行版本管理与部署

### 4.2 LoRA 参数配置

| 参数      | 取值                         |
|---------|----------------------------|
| Rank（r） | 8                          |
| Alpha   | 16                         |
| Dropout | 0.1                        |
| 注入层     | Attention 中的 Query / Value |
| Bias    | None                       |

该配置在表达能力、稳定性与计算效率之间取得平衡，适合中等规模文本分类任务。

---

## 5. 训练设置

### 5.1 核心训练参数

| 参数                  | 取值         |
|---------------------|------------|
| 学习率                 | 2e-4（线性衰减） |
| 训练轮数                | 3 epochs   |
| Batch Size（训练 / 验证） | 16 / 16    |
| 最大序列长度              | 256        |
| Weight Decay        | 0.01       |

### 5.2 参数设计考量

- LoRA 仅更新少量参数，可使用相对较大的学习率
- Epoch 数量控制在较低水平，避免在子样本数据上过拟合
- 序列长度在上下文覆盖与显存占用之间取折中

---

## 6. 评估指标设计

训练过程中采用以下指标：

- **Accuracy**：整体分类正确率
- **Macro F1-score（主指标）**：
    - 对每个情感类别一视同仁
    - 对类别分布不均衡更鲁棒
    - 更能反映模型在情感强度区分上的整体能力

模型选择以 **Macro F1-score** 作为主要依据。

---

## 7. 可复现性与实验控制

为确保实验结果可复现：

* 固定随机种子（Python / NumPy / PyTorch）
* 数据采样与划分过程可控
* 明确记录训练参数与数据规模
* 仅保留最优 adapter 版本

该设计保证模型性能变化可归因于训练策略本身，而非随机扰动。

---

## 8. 训练结果与效果分析（基于真实训练日志）

### 8.1 参数规模

本次训练的参数规模如下：

trainable params：298,757
all params：109,784,842
trainable%：0.2721%

说明本次训练仅更新约 0.27% 的模型参数，完全符合参数高效微调（PEFT）的设计目标。

---

### 8.2 训练损失与梯度稳定性分析

从训练日志可以观察到，训练损失在整个训练过程中呈现出稳定且符合预期的下降趋势。

训练初期（Epoch 0.x），loss 从约 1.62 快速下降至 1.29，并进一步下降至约 1.17，说明 LoRA adapter 能够在冻结基础模型参数的前提下迅速学习到基础情感判别特征。

训练中期（Epoch 1.x），loss 稳定下降并维持在约 1.00 左右，模型开始逐步捕捉不同情感强度等级之间的细粒度差异。

训练后期（Epoch 2.x 至 Epoch 3.0），loss 主要在约 0.89 至 0.98 区间内波动，整体保持稳定，模型逐步进入收敛状态。

在梯度层面，训练过程中记录的梯度范数整体分布在 2.3 至 6.7 的范围内，未出现梯度爆炸或梯度消失问题，说明学习率与 LoRA
参数配置匹配合理，训练过程稳定可控。

---

### 8.3 学习率调度与训练动态分析

本次训练采用线性学习率衰减策略。训练初期较高的学习率有助于 LoRA adapter
快速适配下游任务；随着训练推进，学习率逐步降低，使参数更新更加平滑，从而提升模型在验证集上的稳定性与泛化能力。

从训练损失与验证指标的变化趋势可以看出，学习率调度与模型训练动态之间匹配良好。

---

### 8.4 验证集指标随 Epoch 的变化趋势

模型在验证集上的性能随着训练轮数呈现出清晰的上升趋势。

Epoch 1：Accuracy 约为 0.54，Macro F1 约为 0.50。
Epoch 2：Accuracy 提升至约 0.61，Macro F1 提升至约 0.59。
Epoch 3：Accuracy 维持在约 0.61，Macro F1 进一步提升至约 0.60。

验证指标未出现明显回落，说明模型未发生显著过拟合。

---

### 8.5 多分类情感强度任务下的性能解读

本任务采用五级情感强度分类，文本语义复杂且存在主观噪声。在仅更新约 0.27% 模型参数的前提下，模型在验证集上取得约 0.60 的
Macro F1，说明模型已经能够稳定地区分不同情感强度层级，验证了 LoRA 在复杂多分类任务中的有效性。

---

### 8.6 训练效率与工程表现

从训练日志统计可以看出，训练样本处理速度约为每秒 31 条，训练步数处理速度约为每秒 1.96 步，完整训练过程耗时约 12.7 分钟。

该结果表明 LoRA 微调在通用云 GPU 环境下具备良好的训练效率和工程可行性。

---

### 8.7 训练产物与模型状态

训练完成后，模型成功保存 LoRA adapter 至指定目录。该 adapter 不依赖完整基础模型权重，可独立加载并直接用于推理、Agent
调用或服务化部署。

---

### 8.8 综合结论

综合训练过程与验证结果可以得出结论：在仅更新约 0.27% 模型参数的情况下，LoRA
微调能够稳定、有效地将预训练语言模型适配至五级情感强度分类任务。训练过程数值稳定，验证集指标随训练推进持续提升，最终模型在性能表现与计算效率之间取得了良好平衡。

## 9. Baseline 对比评估（Yelp Test Set）

为定量评估 LoRA 微调带来的真实收益，我们在 **Yelp Review Test split** 上随机抽取 **500 条样本**，对比以下两种模型的推理表现：

* **Baseline 模型**：未进行任何下游微调的 `bert-base-uncased`
* **LoRA 微调模型**：加载本项目训练得到的 LoRA adapter

评估过程中，两种模型使用 **完全相同的 tokenizer、标签映射与推理逻辑**，仅模型参数来源不同，确保对比结果具有可解释性。

### 9.1 评估指标

* **Accuracy**：整体分类准确率
* **Macro F1-score（核心指标）**：

    * 对五个情感强度类别一视同仁
    * 不受类别分布不均衡影响
    * 能更真实反映模型对情感强度层级的区分能力
* **Label Shift 统计**：

    * 统计同一条样本在 Baseline 与 LoRA 模型之间预测标签发生变化的情况
    * 用于分析 LoRA 在情感判断方向与强度上的修正效果

### 9.2 定量评估结果

```
===== Evaluation Results (Yelp Test, N=500) =====
Baseline Accuracy : 0.1840
LoRA Accuracy     : 0.5980

Baseline Macro-F1 : 0.0623
LoRA Macro-F1     : 0.5912

===== Summary =====
Accuracy Gain     : +0.4140
Macro-F1 Gain     : +0.5289
```

可以看到：

* Baseline 模型在五分类情感任务上表现接近随机猜测，Macro-F1 极低
* LoRA 微调模型在 **Accuracy 与 Macro-F1** 两个指标上均取得显著提升
* Macro-F1 提升幅度超过 **+0.52**，表明模型对各情感强度等级的区分能力发生了本质性改善

### 9.3 Label Shift 分析（Baseline → LoRA）

在 500 条测试样本中，预测标签发生变化的主要模式如下：

```
neutral → strong_negative : 140
neutral → strong_positive : 103
neutral → negative        : 86
neutral → positive        : 85
positive → neutral         : 1
```

**分析要点：**

* Baseline 模型存在明显的「中立塌缩」现象，大量样本被预测为 neutral
* LoRA 微调后，模型能够将这些样本重新分配到更符合语义的情感强度区间
* 标签变化主要体现为 **neutral → 明确情感方向**，而非随机波动
* 几乎未出现极端反向误判（如 strong_positive ↔ strong_negative）

### 9.4 对 LoRA 微调效果的结论性解读

该对比实验清晰表明：

1. LoRA 并非仅带来数值层面的微小改进，而是**显著改变了模型的决策结构**
2. 微调模型成功学习到了 Yelp 评论中特有的情感表达与强度分布
3. 在仅更新约 **0.27% 参数** 的前提下，实现了从「不可用」到「可实用」的性能跃迁
4. 该 LoRA adapter 已具备直接用于下游推理、Agent 调用与服务化部署的实际价值
